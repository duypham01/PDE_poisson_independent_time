{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Poisson_independent_time_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1y1QtT4hzrsTvXuS16vH7rxdDXmhKdLE9",
      "authorship_tag": "ABX9TyO1R8dJzFSX5YWixe/3NBxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duypham01/PDE_poisson_independent_time/blob/main/Poisson_independent_time_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5BTg6fnUBZD"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sys\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "import time\n",
        "from itertools import product, combinations\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9C5muxWfCCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2719235-75ef-4c43-8269-3cf317c85382"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY6BMsszfDzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50f774a-1b17-4c68-e73d-fb9952204a8c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkNEr-JrUh7y"
      },
      "source": [
        "class PDENet:\n",
        "    # Init\n",
        "    def __init__(self, xb, yb, ub, x, y, layers):\n",
        "        \n",
        "        # Xb = np.concatenate([xb, yb, ub], 1)\n",
        "        # X = np.concatenate([x, y], 1)\n",
        "        self.dim = 2\n",
        "        \n",
        "        self.xb = xb\n",
        "        self.yb = yb\n",
        "        self.ub = ub\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NN\n",
        "        self.weights, self.biases = self.init_NN(layers)\n",
        "        \n",
        "        # Initialize parameters\n",
        "        # self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        # self.lambda_2 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        self.xyb_tf = tf.placeholder(tf.float32, shape=[None, 2, 1])\n",
        "        self.ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "        self.xy_tf = tf.placeholder(tf.float32, shape=[None, 2, 1])\n",
        "\n",
        "        self.ub_pred, _ , _ = self.net_u(self.xyb_tf)\n",
        "        _ , self.f_u_pred= self.net_f_u(self.xy_tf)\n",
        "        \n",
        "        self.loss = tf.reduce_mean(tf.square(self.ub_tf - self.ub_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_u_pred))\n",
        "                    \n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps})        \n",
        "        self.lossHistogram = []\n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
        "        # self.saver = tf.train.Saver()\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def init_NN(self, layers):\n",
        "        dim = self.dim\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        W = self.xavier_init(size=[layers[0], dim])\n",
        "        b = tf.Variable(tf.zeros([layers[0],1], dtype=tf.float32), dtype=tf.float32)\n",
        "        weights.append(W)  \n",
        "        biases.append(b)\n",
        "        for l in range(1,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l]])\n",
        "            b = tf.Variable(tf.zeros([layers[l],1], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)  \n",
        "        W = self.xavier_init(size=[1, layers[-1]])\n",
        "        b = tf.Variable(tf.zeros([1,1], dtype=tf.float32), dtype=tf.float32)\n",
        "        weights.append(W)  \n",
        "        biases.append(b) \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def net_nn(self, X, weights, biases):\n",
        "        num_layers = len(self.layers)\n",
        "        S = X\n",
        "        for l in range(0,num_layers-1):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            S = tf.tanh(tf.add(tf.matmul(W, S), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        S = tf.add(tf.matmul(W, S), b)\n",
        "        return S\n",
        "\n",
        "    def net_u(self, xy):\n",
        "        u = self.net_nn(xy, self.weights, self.biases)\n",
        "        u = u[:,0]\n",
        "        u_x = tf.gradients(u, xy)[0][:,0]\n",
        "        u_y = tf.gradients(u, xy)[0][:,1]\n",
        "        return u, u_x, u_y\n",
        "        \n",
        "    def net_f_u(self, xy):\n",
        "        u, u_x, u_y = self.net_u(xy)\n",
        "\n",
        "        u_xx = tf.gradients(u_x, xy)[0][:,0]\n",
        "        u_yy = tf.gradients(u_y, xy)[0][:,1]\n",
        "        f_u = (-1.0)*(u_xx + u_yy) - 2.0*np.pi*np.pi*tf.math.sin(np.pi*xy[:,0])*tf.math.sin(np.pi*xy[:,1])\n",
        "        print(f_u)\n",
        "        \n",
        "        return u, f_u\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss: %.3e' % (loss))\n",
        "        self.lossHistogram.append(loss)\n",
        "      \n",
        "    def train(self, nIter): \n",
        "\n",
        "        tf_dict = {self.xyb_tf: np.concatenate([self.xb, self.yb], 1), self.ub_tf: self.ub,\n",
        "                   self.xy_tf: np.concatenate([self.x, self.y], 1)}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            # if it % 10 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            loss_value = self.sess.run(self.loss, tf_dict)\n",
        "            print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                    (it, loss_value, elapsed))\n",
        "            self.lossHistogram.append(loss_value)\n",
        "            start_time = time.time()\n",
        "            \n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss],\n",
        "                                loss_callback = self.callback)\n",
        "        \n",
        "        # self.saver.save(self.sess, 'my-model.ckpt')\n",
        "    \n",
        "    def predict(self, x, y):\n",
        "        \n",
        "        tf_dict = {self.xyb_tf: np.concatenate([x, y], 1)}\n",
        "        \n",
        "        u = self.sess.run(self.ub_pred, tf_dict)\n",
        "\n",
        "        # tf_dict = {self.x_tf: x, self.y_tf: y}\n",
        "        \n",
        "        # f_u = self.sess.run(self.f_u_pred, tf_dict)\n",
        "        \n",
        "        return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE9r99pn9jjY"
      },
      "source": [
        "class sampling_from_rectangle:\n",
        "\tdef __init__(self, x_range, y_range):\n",
        "\t\tself.x_range = x_range\n",
        "\t\tself.y_range = y_range\n",
        "\n",
        "\tdef interior_samples(self, batchsize):\n",
        "\t\tint_draw_x = np.random.uniform(self.x_range[0], self.x_range[1], batchsize)\n",
        "\t\tint_draw_y = np.random.uniform(self.y_range[0], self.y_range[1], batchsize)\n",
        "\n",
        "\t\treturn int_draw_x, int_draw_y\n",
        "\n",
        "\tdef boundary_samples(self, batchsize):\n",
        "\t\ta = self.x_range[1]-self.x_range[0]\n",
        "\t\tb = self.y_range[1]-self.y_range[0]\n",
        "\n",
        "\t\tdraw_perimeter = np.random.uniform(0, 2*(a + b), batchsize)\n",
        "\n",
        "\t\tdraw = []\n",
        "\n",
        "\t\tfor i in draw_perimeter:\n",
        "\t\t\tif i < a:\n",
        "\t\t\t\tdraw.append([i+ self.x_range[0], self.y_range[0]])\n",
        "\t\t\telif a <= i and i < a+b:\n",
        "\t\t\t\tdraw.append([self.x_range[1], (i-a) + self.y_range[0]])\n",
        "\t\t\telif a+b <= i and i < 2*a+b:\n",
        "\t\t\t\tdraw.append([self.x_range[1] - (i-(a+b)), self.y_range[1]])\n",
        "\t\t\telif 2*a+b <= i and i<= 2*a+2*b:\n",
        "\t\t\t\tdraw.append([self.x_range[0], self.y_range[1] - (i-(2*a+b))])\n",
        "\n",
        "\t\treturn np.array(draw)[:, 0], np.array(draw)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6TcDkvs9mrk",
        "outputId": "ce2577b0-ea65-439f-d2d8-b500143d51da"
      },
      "source": [
        "sampler = sampling_from_rectangle([0.0, 1.0], [0.0, 1.0])\n",
        "N = 500;\n",
        "filename = 'data_'\n",
        "\n",
        "with open(filename + str(N) + '.csv', mode='w') as f:\n",
        "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "    bou_draw_x, bou_draw_y = sampler.boundary_samples(N)\n",
        "    int_draw_x, int_draw_y = sampler.interior_samples(N)\n",
        "    \n",
        "    for i in range(N):\n",
        "        csv_writer.writerow([int_draw_x[i], int_draw_y[i], bou_draw_x[i], bou_draw_y[i], 0.0])\n",
        "\n",
        "dataset = np.genfromtxt('data_500.csv', delimiter=',')\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.93654143 0.75526375 0.46605683 0.         0.        ]\n",
            " [0.85086658 0.70998406 0.14026683 1.         0.        ]\n",
            " [0.82433124 0.32229588 0.         0.90319176 0.        ]\n",
            " ...\n",
            " [0.13525493 0.45658654 1.         0.25739073 0.        ]\n",
            " [0.14991684 0.18672873 1.         0.1491583  0.        ]\n",
            " [0.95823019 0.36411965 0.08488416 0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWo16jltr0eI"
      },
      "source": [
        "def splitData(data):\n",
        "    x = []\n",
        "    y = []\n",
        "    xb = []\n",
        "    yb = []\n",
        "    ub = []\n",
        "    for row in data:\n",
        "        if (row[0] == 0. or row[1] == 0. or row[0] == 1. or row[1] == 1.):\n",
        "            xb.append(row[0])\n",
        "            yb.append(row[1])\n",
        "            ub.append(0.0)\n",
        "        else:\n",
        "            x.append(row[0])\n",
        "            y.append(row[1])\n",
        "    return np.array(x), np.array(y), np.array(xb), np.array(yb), np.array(ub)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNt9KH73oJ15"
      },
      "source": [
        "dataset = np.genfromtxt('modified_triangle_data.txt', delimiter=',')\n",
        "x,y,xb,yb,ub = splitData(dataset)\n",
        "x = x.reshape((x.size, 1, 1))\n",
        "y = y.reshape((y.size, 1, 1))\n",
        "xb = xb.reshape((xb.size, 1, 1))\n",
        "yb = yb.reshape((yb.size, 1, 1))\n",
        "ub = ub.reshape((ub.size, 1))\n",
        "layers = [32, 32, 32, 32]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdrlTE8jqrgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90c4d796-50ae-4e79-da09-cecb8a21473f"
      },
      "source": [
        "model = PDENet(xb, yb, ub, x, y, layers)\n",
        "start_time = time.time()                \n",
        "model.train(0)\n",
        "elapsed = time.time() - start_time                \n",
        "print('Training time: %.4f' % (elapsed))\n",
        "losses = np.array(model.lossHistogram)\n",
        "losses = losses.reshape(len(losses))\n",
        "epochs = losses.size\n",
        "x_epochs = [i + 1 for i in range(epochs)]\n",
        "plt.xticks(np.arange(0, epochs+1 , 500))\n",
        "\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x_epochs, losses, color = 'blue')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "Tensor(\"sub_51:0\", shape=(?, 1), dtype=float32)\n",
            "Loss: 9.527e+01\n",
            "Loss: 7.874e+01\n",
            "Loss: 7.489e+01\n",
            "Loss: 5.749e+01\n",
            "Loss: 1.569e+02\n",
            "Loss: 1.439e+02\n",
            "Loss: 4.614e+01\n",
            "Loss: 3.382e+01\n",
            "Loss: 4.446e+02\n",
            "Loss: 3.035e+01\n",
            "Loss: 3.316e+01\n",
            "Loss: 2.630e+01\n",
            "Loss: 2.529e+01\n",
            "Loss: 2.305e+01\n",
            "Loss: 2.136e+01\n",
            "Loss: 2.036e+01\n",
            "Loss: 1.768e+01\n",
            "Loss: 5.243e+02\n",
            "Loss: 1.363e+01\n",
            "Loss: 1.740e+01\n",
            "Loss: 1.091e+01\n",
            "Loss: 1.341e+01\n",
            "Loss: 9.620e+00\n",
            "Loss: 1.032e+01\n",
            "Loss: 9.280e+00\n",
            "Loss: 9.157e+00\n",
            "Loss: 8.916e+00\n",
            "Loss: 8.470e+00\n",
            "Loss: 7.656e+00\n",
            "Loss: 7.191e+00\n",
            "Loss: 6.762e+00\n",
            "Loss: 6.162e+00\n",
            "Loss: 5.671e+00\n",
            "Loss: 5.370e+00\n",
            "Loss: 5.198e+00\n",
            "Loss: 5.089e+00\n",
            "Loss: 4.967e+00\n",
            "Loss: 4.451e+00\n",
            "Loss: 4.023e+00\n",
            "Loss: 3.848e+00\n",
            "Loss: 4.580e+00\n",
            "Loss: 3.279e+00\n",
            "Loss: 2.811e+00\n",
            "Loss: 2.581e+00\n",
            "Loss: 2.173e+00\n",
            "Loss: 1.916e+00\n",
            "Loss: 1.779e+00\n",
            "Loss: 1.609e+00\n",
            "Loss: 1.402e+00\n",
            "Loss: 1.229e+00\n",
            "Loss: 1.124e+00\n",
            "Loss: 1.093e+00\n",
            "Loss: 1.012e+00\n",
            "Loss: 9.689e-01\n",
            "Loss: 8.953e-01\n",
            "Loss: 7.995e-01\n",
            "Loss: 7.068e-01\n",
            "Loss: 6.393e-01\n",
            "Loss: 6.143e-01\n",
            "Loss: 5.991e-01\n",
            "Loss: 5.711e-01\n",
            "Loss: 5.214e-01\n",
            "Loss: 4.613e-01\n",
            "Loss: 4.042e-01\n",
            "Loss: 3.733e-01\n",
            "Loss: 3.578e-01\n",
            "Loss: 3.398e-01\n",
            "Loss: 3.080e-01\n",
            "Loss: 2.833e-01\n",
            "Loss: 2.603e-01\n",
            "Loss: 2.502e-01\n",
            "Loss: 2.442e-01\n",
            "Loss: 2.392e-01\n",
            "Loss: 2.286e-01\n",
            "Loss: 2.109e-01\n",
            "Loss: 1.943e-01\n",
            "Loss: 1.852e-01\n",
            "Loss: 1.776e-01\n",
            "Loss: 1.717e-01\n",
            "Loss: 1.674e-01\n",
            "Loss: 1.628e-01\n",
            "Loss: 1.573e-01\n",
            "Loss: 1.560e-01\n",
            "Loss: 1.542e-01\n",
            "Loss: 1.472e-01\n",
            "Loss: 1.393e-01\n",
            "Loss: 1.303e-01\n",
            "Loss: 1.258e-01\n",
            "Loss: 1.219e-01\n",
            "Loss: 1.176e-01\n",
            "Loss: 1.124e-01\n",
            "Loss: 1.078e-01\n",
            "Loss: 1.004e-01\n",
            "Loss: 9.426e-02\n",
            "Loss: 9.047e-02\n",
            "Loss: 8.873e-02\n",
            "Loss: 8.767e-02\n",
            "Loss: 8.705e-02\n",
            "Loss: 8.631e-02\n",
            "Loss: 8.493e-02\n",
            "Loss: 8.338e-02\n",
            "Loss: 8.143e-02\n",
            "Loss: 7.769e-02\n",
            "Loss: 7.367e-02\n",
            "Loss: 7.012e-02\n",
            "Loss: 6.690e-02\n",
            "Loss: 6.336e-02\n",
            "Loss: 6.092e-02\n",
            "Loss: 5.903e-02\n",
            "Loss: 5.797e-02\n",
            "Loss: 5.714e-02\n",
            "Loss: 5.630e-02\n",
            "Loss: 5.585e-02\n",
            "Loss: 5.534e-02\n",
            "Loss: 5.471e-02\n",
            "Loss: 5.384e-02\n",
            "Loss: 5.235e-02\n",
            "Loss: 5.138e-02\n",
            "Loss: 5.058e-02\n",
            "Loss: 5.027e-02\n",
            "Loss: 4.991e-02\n",
            "Loss: 4.950e-02\n",
            "Loss: 4.828e-02\n",
            "Loss: 4.686e-02\n",
            "Loss: 4.557e-02\n",
            "Loss: 4.464e-02\n",
            "Loss: 4.446e-02\n",
            "Loss: 4.402e-02\n",
            "Loss: 4.384e-02\n",
            "Loss: 4.358e-02\n",
            "Loss: 4.279e-02\n",
            "Loss: 4.195e-02\n",
            "Loss: 4.096e-02\n",
            "Loss: 4.031e-02\n",
            "Loss: 3.970e-02\n",
            "Loss: 3.867e-02\n",
            "Loss: 3.685e-02\n",
            "Loss: 3.549e-02\n",
            "Loss: 3.494e-02\n",
            "Loss: 3.465e-02\n",
            "Loss: 3.453e-02\n",
            "Loss: 3.424e-02\n",
            "Loss: 3.314e-02\n",
            "Loss: 3.205e-02\n",
            "Loss: 3.115e-02\n",
            "Loss: 3.059e-02\n",
            "Loss: 3.041e-02\n",
            "Loss: 3.029e-02\n",
            "Loss: 2.993e-02\n",
            "Loss: 2.946e-02\n",
            "Loss: 2.906e-02\n",
            "Loss: 2.873e-02\n",
            "Loss: 2.844e-02\n",
            "Loss: 2.806e-02\n",
            "Loss: 2.763e-02\n",
            "Loss: 2.682e-02\n",
            "Loss: 2.605e-02\n",
            "Loss: 2.549e-02\n",
            "Loss: 2.513e-02\n",
            "Loss: 2.483e-02\n",
            "Loss: 2.458e-02\n",
            "Loss: 2.429e-02\n",
            "Loss: 2.392e-02\n",
            "Loss: 2.353e-02\n",
            "Loss: 2.326e-02\n",
            "Loss: 2.290e-02\n",
            "Loss: 2.244e-02\n",
            "Loss: 2.203e-02\n",
            "Loss: 2.180e-02\n",
            "Loss: 2.167e-02\n",
            "Loss: 2.154e-02\n",
            "Loss: 2.138e-02\n",
            "Loss: 2.118e-02\n",
            "Loss: 2.088e-02\n",
            "Loss: 2.064e-02\n",
            "Loss: 2.058e-02\n",
            "Loss: 2.042e-02\n",
            "Loss: 2.034e-02\n",
            "Loss: 2.025e-02\n",
            "Loss: 2.011e-02\n",
            "Loss: 1.962e-02\n",
            "Loss: 1.905e-02\n",
            "Loss: 1.848e-02\n",
            "Loss: 1.829e-02\n",
            "Loss: 1.814e-02\n",
            "Loss: 1.809e-02\n",
            "Loss: 1.804e-02\n",
            "Loss: 1.798e-02\n",
            "Loss: 1.790e-02\n",
            "Loss: 1.777e-02\n",
            "Loss: 1.759e-02\n",
            "Loss: 1.731e-02\n",
            "Loss: 1.697e-02\n",
            "Loss: 1.687e-02\n",
            "Loss: 1.680e-02\n",
            "Loss: 1.660e-02\n",
            "Loss: 1.647e-02\n",
            "Loss: 1.639e-02\n",
            "Loss: 1.630e-02\n",
            "Loss: 1.620e-02\n",
            "Loss: 1.605e-02\n",
            "Loss: 1.588e-02\n",
            "Loss: 1.574e-02\n",
            "Loss: 1.562e-02\n",
            "Loss: 1.547e-02\n",
            "Loss: 1.530e-02\n",
            "Loss: 1.508e-02\n",
            "Loss: 1.498e-02\n",
            "Loss: 1.490e-02\n",
            "Loss: 1.463e-02\n",
            "Loss: 1.441e-02\n",
            "Loss: 1.428e-02\n",
            "Loss: 1.418e-02\n",
            "Loss: 1.411e-02\n",
            "Loss: 1.406e-02\n",
            "Loss: 1.397e-02\n",
            "Loss: 1.386e-02\n",
            "Loss: 1.375e-02\n",
            "Loss: 1.363e-02\n",
            "Loss: 1.351e-02\n",
            "Loss: 1.339e-02\n",
            "Loss: 1.327e-02\n",
            "Loss: 1.322e-02\n",
            "Loss: 1.319e-02\n",
            "Loss: 1.317e-02\n",
            "Loss: 1.315e-02\n",
            "Loss: 1.309e-02\n",
            "Loss: 1.301e-02\n",
            "Loss: 1.283e-02\n",
            "Loss: 1.278e-02\n",
            "Loss: 1.266e-02\n",
            "Loss: 1.236e-02\n",
            "Loss: 1.204e-02\n",
            "Loss: 1.184e-02\n",
            "Loss: 1.163e-02\n",
            "Loss: 1.155e-02\n",
            "Loss: 1.162e-02\n",
            "Loss: 1.151e-02\n",
            "Loss: 1.145e-02\n",
            "Loss: 1.139e-02\n",
            "Loss: 1.132e-02\n",
            "Loss: 1.126e-02\n",
            "Loss: 1.122e-02\n",
            "Loss: 1.119e-02\n",
            "Loss: 1.115e-02\n",
            "Loss: 1.103e-02\n",
            "Loss: 1.082e-02\n",
            "Loss: 1.054e-02\n",
            "Loss: 1.031e-02\n",
            "Loss: 1.037e-02\n",
            "Loss: 1.020e-02\n",
            "Loss: 1.011e-02\n",
            "Loss: 1.009e-02\n",
            "Loss: 1.002e-02\n",
            "Loss: 9.970e-03\n",
            "Loss: 9.906e-03\n",
            "Loss: 9.804e-03\n",
            "Loss: 9.741e-03\n",
            "Loss: 9.654e-03\n",
            "Loss: 9.565e-03\n",
            "Loss: 9.467e-03\n",
            "Loss: 9.351e-03\n",
            "Loss: 9.284e-03\n",
            "Loss: 9.213e-03\n",
            "Loss: 9.170e-03\n",
            "Loss: 9.104e-03\n",
            "Loss: 9.006e-03\n",
            "Loss: 8.861e-03\n",
            "Loss: 8.688e-03\n",
            "Loss: 8.704e-03\n",
            "Loss: 8.631e-03\n",
            "Loss: 8.611e-03\n",
            "Loss: 8.580e-03\n",
            "Loss: 8.517e-03\n",
            "Loss: 8.482e-03\n",
            "Loss: 8.441e-03\n",
            "Loss: 8.384e-03\n",
            "Loss: 8.262e-03\n",
            "Loss: 8.126e-03\n",
            "Loss: 8.022e-03\n",
            "Loss: 7.932e-03\n",
            "Loss: 7.913e-03\n",
            "Loss: 7.944e-03\n",
            "Loss: 7.873e-03\n",
            "Loss: 7.857e-03\n",
            "Loss: 7.804e-03\n",
            "Loss: 7.762e-03\n",
            "Loss: 7.689e-03\n",
            "Loss: 7.600e-03\n",
            "Loss: 7.526e-03\n",
            "Loss: 7.480e-03\n",
            "Loss: 7.425e-03\n",
            "Loss: 7.387e-03\n",
            "Loss: 7.342e-03\n",
            "Loss: 7.287e-03\n",
            "Loss: 7.226e-03\n",
            "Loss: 7.142e-03\n",
            "Loss: 7.061e-03\n",
            "Loss: 6.937e-03\n",
            "Loss: 6.891e-03\n",
            "Loss: 6.823e-03\n",
            "Loss: 6.791e-03\n",
            "Loss: 6.755e-03\n",
            "Loss: 6.721e-03\n",
            "Loss: 6.701e-03\n",
            "Loss: 6.682e-03\n",
            "Loss: 6.660e-03\n",
            "Loss: 6.640e-03\n",
            "Loss: 6.626e-03\n",
            "Loss: 6.605e-03\n",
            "Loss: 6.592e-03\n",
            "Loss: 6.576e-03\n",
            "Loss: 6.541e-03\n",
            "Loss: 6.519e-03\n",
            "Loss: 6.480e-03\n",
            "Loss: 6.424e-03\n",
            "Loss: 6.367e-03\n",
            "Loss: 6.290e-03\n",
            "Loss: 6.273e-03\n",
            "Loss: 6.255e-03\n",
            "Loss: 6.196e-03\n",
            "Loss: 6.164e-03\n",
            "Loss: 6.136e-03\n",
            "Loss: 6.101e-03\n",
            "Loss: 6.058e-03\n",
            "Loss: 5.990e-03\n",
            "Loss: 5.921e-03\n",
            "Loss: 5.828e-03\n",
            "Loss: 5.831e-03\n",
            "Loss: 5.777e-03\n",
            "Loss: 5.764e-03\n",
            "Loss: 5.728e-03\n",
            "Loss: 5.709e-03\n",
            "Loss: 5.621e-03\n",
            "Loss: 5.584e-03\n",
            "Loss: 5.552e-03\n",
            "Loss: 5.521e-03\n",
            "Loss: 5.493e-03\n",
            "Loss: 5.454e-03\n",
            "Loss: 5.421e-03\n",
            "Loss: 5.383e-03\n",
            "Loss: 5.366e-03\n",
            "Loss: 5.340e-03\n",
            "Loss: 5.289e-03\n",
            "Loss: 5.260e-03\n",
            "Loss: 5.224e-03\n",
            "Loss: 5.187e-03\n",
            "Loss: 5.167e-03\n",
            "Loss: 5.151e-03\n",
            "Loss: 5.117e-03\n",
            "Loss: 5.074e-03\n",
            "Loss: 4.961e-03\n",
            "Loss: 4.851e-03\n",
            "Loss: 4.776e-03\n",
            "Loss: 4.714e-03\n",
            "Loss: 4.666e-03\n",
            "Loss: 4.619e-03\n",
            "Loss: 4.574e-03\n",
            "Loss: 4.530e-03\n",
            "Loss: 4.480e-03\n",
            "Loss: 4.442e-03\n",
            "Loss: 4.386e-03\n",
            "Loss: 4.335e-03\n",
            "Loss: 4.274e-03\n",
            "Loss: 4.221e-03\n",
            "Loss: 4.175e-03\n",
            "Loss: 4.130e-03\n",
            "Loss: 4.082e-03\n",
            "Loss: 4.026e-03\n",
            "Loss: 3.944e-03\n",
            "Loss: 3.887e-03\n",
            "Loss: 3.872e-03\n",
            "Loss: 3.854e-03\n",
            "Loss: 3.823e-03\n",
            "Loss: 3.790e-03\n",
            "Loss: 3.764e-03\n",
            "Loss: 3.740e-03\n",
            "Loss: 3.720e-03\n",
            "Loss: 3.699e-03\n",
            "Loss: 3.669e-03\n",
            "Loss: 3.636e-03\n",
            "Loss: 3.591e-03\n",
            "Loss: 3.563e-03\n",
            "Loss: 3.537e-03\n",
            "Loss: 3.510e-03\n",
            "Loss: 3.405e-03\n",
            "Loss: 3.341e-03\n",
            "Loss: 3.242e-03\n",
            "Loss: 3.095e-03\n",
            "Loss: 3.024e-03\n",
            "Loss: 2.965e-03\n",
            "Loss: 2.942e-03\n",
            "Loss: 2.917e-03\n",
            "Loss: 2.872e-03\n",
            "Loss: 2.837e-03\n",
            "Loss: 2.813e-03\n",
            "Loss: 2.781e-03\n",
            "Loss: 2.753e-03\n",
            "Loss: 2.724e-03\n",
            "Loss: 2.685e-03\n",
            "Loss: 2.643e-03\n",
            "Loss: 2.600e-03\n",
            "Loss: 2.555e-03\n",
            "Loss: 2.516e-03\n",
            "Loss: 2.472e-03\n",
            "Loss: 2.439e-03\n",
            "Loss: 2.401e-03\n",
            "Loss: 2.365e-03\n",
            "Loss: 2.331e-03\n",
            "Loss: 2.315e-03\n",
            "Loss: 2.285e-03\n",
            "Loss: 2.267e-03\n",
            "Loss: 2.237e-03\n",
            "Loss: 2.206e-03\n",
            "Loss: 2.173e-03\n",
            "Loss: 2.145e-03\n",
            "Loss: 2.122e-03\n",
            "Loss: 2.097e-03\n",
            "Loss: 2.075e-03\n",
            "Loss: 2.049e-03\n",
            "Loss: 2.021e-03\n",
            "Loss: 2.005e-03\n",
            "Loss: 1.992e-03\n",
            "Loss: 1.975e-03\n",
            "Loss: 1.957e-03\n",
            "Loss: 1.935e-03\n",
            "Loss: 1.931e-03\n",
            "Loss: 1.918e-03\n",
            "Loss: 1.913e-03\n",
            "Loss: 1.902e-03\n",
            "Loss: 1.887e-03\n",
            "Loss: 1.867e-03\n",
            "Loss: 1.843e-03\n",
            "Loss: 1.814e-03\n",
            "Loss: 1.785e-03\n",
            "Loss: 1.753e-03\n",
            "Loss: 1.738e-03\n",
            "Loss: 1.728e-03\n",
            "Loss: 1.720e-03\n",
            "Loss: 1.711e-03\n",
            "Loss: 1.693e-03\n",
            "Loss: 1.686e-03\n",
            "Loss: 1.674e-03\n",
            "Loss: 1.657e-03\n",
            "Loss: 1.645e-03\n",
            "Loss: 1.635e-03\n",
            "Loss: 1.624e-03\n",
            "Loss: 1.615e-03\n",
            "Loss: 1.606e-03\n",
            "Loss: 1.591e-03\n",
            "Loss: 1.572e-03\n",
            "Loss: 1.548e-03\n",
            "Loss: 1.526e-03\n",
            "Loss: 1.515e-03\n",
            "Loss: 1.491e-03\n",
            "Loss: 1.484e-03\n",
            "Loss: 1.478e-03\n",
            "Loss: 1.471e-03\n",
            "Loss: 1.464e-03\n",
            "Loss: 1.453e-03\n",
            "Loss: 1.437e-03\n",
            "Loss: 1.423e-03\n",
            "Loss: 1.411e-03\n",
            "Loss: 1.394e-03\n",
            "Loss: 1.373e-03\n",
            "Loss: 1.358e-03\n",
            "Loss: 1.341e-03\n",
            "Loss: 1.331e-03\n",
            "Loss: 1.324e-03\n",
            "Loss: 1.317e-03\n",
            "Loss: 1.307e-03\n",
            "Loss: 1.288e-03\n",
            "Loss: 1.276e-03\n",
            "Loss: 1.266e-03\n",
            "Loss: 1.255e-03\n",
            "Loss: 1.248e-03\n",
            "Loss: 1.224e-03\n",
            "Loss: 1.199e-03\n",
            "Loss: 1.169e-03\n",
            "Loss: 1.144e-03\n",
            "Loss: 1.134e-03\n",
            "Loss: 1.146e-03\n",
            "Loss: 1.124e-03\n",
            "Loss: 1.116e-03\n",
            "Loss: 1.112e-03\n",
            "Loss: 1.108e-03\n",
            "Loss: 1.104e-03\n",
            "Loss: 1.098e-03\n",
            "Loss: 1.090e-03\n",
            "Loss: 1.081e-03\n",
            "Loss: 1.072e-03\n",
            "Loss: 1.058e-03\n",
            "Loss: 1.036e-03\n",
            "Loss: 1.001e-03\n",
            "Loss: 9.932e-04\n",
            "Loss: 9.718e-04\n",
            "Loss: 9.681e-04\n",
            "Loss: 9.637e-04\n",
            "Loss: 9.580e-04\n",
            "Loss: 9.462e-04\n",
            "Loss: 9.281e-04\n",
            "Loss: 9.150e-04\n",
            "Loss: 8.979e-04\n",
            "Loss: 8.927e-04\n",
            "Loss: 8.861e-04\n",
            "Loss: 8.816e-04\n",
            "Loss: 8.776e-04\n",
            "Loss: 8.733e-04\n",
            "Loss: 8.707e-04\n",
            "Loss: 8.681e-04\n",
            "Loss: 8.661e-04\n",
            "Loss: 8.644e-04\n",
            "Loss: 8.623e-04\n",
            "Loss: 8.586e-04\n",
            "Loss: 8.564e-04\n",
            "Loss: 8.508e-04\n",
            "Loss: 8.481e-04\n",
            "Loss: 8.452e-04\n",
            "Loss: 8.411e-04\n",
            "Loss: 8.324e-04\n",
            "Loss: 8.196e-04\n",
            "Loss: 8.007e-04\n",
            "Loss: 7.812e-04\n",
            "Loss: 7.634e-04\n",
            "Loss: 7.618e-04\n",
            "Loss: 7.538e-04\n",
            "Loss: 7.457e-04\n",
            "Loss: 7.399e-04\n",
            "Loss: 7.320e-04\n",
            "Loss: 7.267e-04\n",
            "Loss: 7.220e-04\n",
            "Loss: 7.131e-04\n",
            "Loss: 7.110e-04\n",
            "Loss: 7.071e-04\n",
            "Loss: 7.060e-04\n",
            "Loss: 7.044e-04\n",
            "Loss: 7.020e-04\n",
            "Loss: 6.989e-04\n",
            "Loss: 6.951e-04\n",
            "Loss: 6.915e-04\n",
            "Loss: 6.872e-04\n",
            "Loss: 6.850e-04\n",
            "Loss: 6.795e-04\n",
            "Loss: 6.748e-04\n",
            "Loss: 6.671e-04\n",
            "Loss: 6.611e-04\n",
            "Loss: 6.520e-04\n",
            "Loss: 6.473e-04\n",
            "Loss: 6.394e-04\n",
            "Loss: 6.400e-04\n",
            "Loss: 6.357e-04\n",
            "Loss: 6.298e-04\n",
            "Loss: 6.260e-04\n",
            "Loss: 6.234e-04\n",
            "Loss: 6.216e-04\n",
            "Loss: 6.200e-04\n",
            "Loss: 6.184e-04\n",
            "Loss: 6.158e-04\n",
            "Loss: 6.138e-04\n",
            "Loss: 6.120e-04\n",
            "Loss: 6.102e-04\n",
            "Loss: 6.081e-04\n",
            "Loss: 6.054e-04\n",
            "Loss: 6.032e-04\n",
            "Loss: 5.984e-04\n",
            "Loss: 5.947e-04\n",
            "Loss: 5.908e-04\n",
            "Loss: 5.883e-04\n",
            "Loss: 5.854e-04\n",
            "Loss: 5.819e-04\n",
            "Loss: 5.773e-04\n",
            "Loss: 5.713e-04\n",
            "Loss: 5.692e-04\n",
            "Loss: 5.672e-04\n",
            "Loss: 5.661e-04\n",
            "Loss: 5.643e-04\n",
            "Loss: 5.631e-04\n",
            "Loss: 5.619e-04\n",
            "Loss: 5.598e-04\n",
            "Loss: 5.562e-04\n",
            "Loss: 5.495e-04\n",
            "Loss: 5.409e-04\n",
            "Loss: 5.331e-04\n",
            "Loss: 5.288e-04\n",
            "Loss: 5.238e-04\n",
            "Loss: 5.209e-04\n",
            "Loss: 5.173e-04\n",
            "Loss: 5.117e-04\n",
            "Loss: 5.056e-04\n",
            "Loss: 4.989e-04\n",
            "Loss: 4.931e-04\n",
            "Loss: 4.907e-04\n",
            "Loss: 4.853e-04\n",
            "Loss: 4.826e-04\n",
            "Loss: 4.807e-04\n",
            "Loss: 4.794e-04\n",
            "Loss: 4.783e-04\n",
            "Loss: 4.766e-04\n",
            "Loss: 4.739e-04\n",
            "Loss: 4.717e-04\n",
            "Loss: 4.686e-04\n",
            "Loss: 4.643e-04\n",
            "Loss: 4.656e-04\n",
            "Loss: 4.633e-04\n",
            "Loss: 4.617e-04\n",
            "Loss: 4.600e-04\n",
            "Loss: 4.581e-04\n",
            "Loss: 4.559e-04\n",
            "Loss: 4.531e-04\n",
            "Loss: 4.510e-04\n",
            "Loss: 4.489e-04\n",
            "Loss: 4.469e-04\n",
            "Loss: 4.449e-04\n",
            "Loss: 4.436e-04\n",
            "Loss: 4.428e-04\n",
            "Loss: 4.413e-04\n",
            "Loss: 4.397e-04\n",
            "Loss: 4.380e-04\n",
            "Loss: 4.356e-04\n",
            "Loss: 4.320e-04\n",
            "Loss: 4.281e-04\n",
            "Loss: 4.237e-04\n",
            "Loss: 4.192e-04\n",
            "Loss: 4.155e-04\n",
            "Loss: 4.111e-04\n",
            "Loss: 4.050e-04\n",
            "Loss: 3.974e-04\n",
            "Loss: 3.901e-04\n",
            "Loss: 3.860e-04\n",
            "Loss: 3.776e-04\n",
            "Loss: 3.732e-04\n",
            "Loss: 3.694e-04\n",
            "Loss: 3.644e-04\n",
            "Loss: 3.613e-04\n",
            "Loss: 3.585e-04\n",
            "Loss: 3.553e-04\n",
            "Loss: 3.529e-04\n",
            "Loss: 3.499e-04\n",
            "Loss: 3.469e-04\n",
            "Loss: 3.430e-04\n",
            "Loss: 3.370e-04\n",
            "Loss: 3.334e-04\n",
            "Loss: 3.303e-04\n",
            "Loss: 3.279e-04\n",
            "Loss: 3.259e-04\n",
            "Loss: 3.240e-04\n",
            "Loss: 3.224e-04\n",
            "Loss: 3.203e-04\n",
            "Loss: 3.183e-04\n",
            "Loss: 3.144e-04\n",
            "Loss: 3.137e-04\n",
            "Loss: 3.093e-04\n",
            "Loss: 3.075e-04\n",
            "Loss: 3.045e-04\n",
            "Loss: 3.050e-04\n",
            "Loss: 3.030e-04\n",
            "Loss: 3.006e-04\n",
            "Loss: 2.983e-04\n",
            "Loss: 2.961e-04\n",
            "Loss: 2.937e-04\n",
            "Loss: 2.917e-04\n",
            "Loss: 2.898e-04\n",
            "Loss: 2.890e-04\n",
            "Loss: 2.880e-04\n",
            "Loss: 2.865e-04\n",
            "Loss: 2.850e-04\n",
            "Loss: 2.835e-04\n",
            "Loss: 2.817e-04\n",
            "Loss: 2.917e-04\n",
            "Loss: 2.805e-04\n",
            "Loss: 2.784e-04\n",
            "Loss: 2.764e-04\n",
            "Loss: 2.743e-04\n",
            "Loss: 2.714e-04\n",
            "Loss: 2.685e-04\n",
            "Loss: 2.660e-04\n",
            "Loss: 2.630e-04\n",
            "Loss: 2.591e-04\n",
            "Loss: 2.544e-04\n",
            "Loss: 2.609e-04\n",
            "Loss: 2.519e-04\n",
            "Loss: 2.483e-04\n",
            "Loss: 2.452e-04\n",
            "Loss: 2.437e-04\n",
            "Loss: 2.422e-04\n",
            "Loss: 2.401e-04\n",
            "Loss: 2.386e-04\n",
            "Loss: 2.353e-04\n",
            "Loss: 2.325e-04\n",
            "Loss: 2.291e-04\n",
            "Loss: 2.277e-04\n",
            "Loss: 2.262e-04\n",
            "Loss: 2.260e-04\n",
            "Loss: 2.243e-04\n",
            "Loss: 2.228e-04\n",
            "Loss: 2.214e-04\n",
            "Loss: 2.192e-04\n",
            "Loss: 2.171e-04\n",
            "Loss: 2.154e-04\n",
            "Loss: 2.144e-04\n",
            "Loss: 2.133e-04\n",
            "Loss: 2.125e-04\n",
            "Loss: 2.110e-04\n",
            "Loss: 2.094e-04\n",
            "Loss: 2.076e-04\n",
            "Loss: 2.064e-04\n",
            "Loss: 2.058e-04\n",
            "Loss: 2.045e-04\n",
            "Loss: 2.036e-04\n",
            "Loss: 2.024e-04\n",
            "Loss: 2.007e-04\n",
            "Loss: 1.996e-04\n",
            "Loss: 1.983e-04\n",
            "Loss: 1.976e-04\n",
            "Loss: 1.971e-04\n",
            "Loss: 1.964e-04\n",
            "Loss: 1.955e-04\n",
            "Loss: 1.943e-04\n",
            "Loss: 1.929e-04\n",
            "Loss: 1.919e-04\n",
            "Loss: 1.913e-04\n",
            "Loss: 1.907e-04\n",
            "Loss: 1.900e-04\n",
            "Loss: 1.888e-04\n",
            "Loss: 1.875e-04\n",
            "Loss: 1.869e-04\n",
            "Loss: 1.864e-04\n",
            "Loss: 1.860e-04\n",
            "Loss: 1.851e-04\n",
            "Loss: 1.841e-04\n",
            "Loss: 1.826e-04\n",
            "Loss: 1.808e-04\n",
            "Loss: 1.793e-04\n",
            "Loss: 1.782e-04\n",
            "Loss: 1.768e-04\n",
            "Loss: 1.752e-04\n",
            "Loss: 1.723e-04\n",
            "Loss: 1.703e-04\n",
            "Loss: 1.691e-04\n",
            "Loss: 1.685e-04\n",
            "Loss: 1.680e-04\n",
            "Loss: 1.666e-04\n",
            "Loss: 1.650e-04\n",
            "Loss: 1.628e-04\n",
            "Loss: 1.606e-04\n",
            "Loss: 1.581e-04\n",
            "Loss: 1.542e-04\n",
            "Loss: 1.500e-04\n",
            "Loss: 1.473e-04\n",
            "Loss: 1.442e-04\n",
            "Loss: 1.411e-04\n",
            "Loss: 1.376e-04\n",
            "Loss: 1.359e-04\n",
            "Loss: 1.335e-04\n",
            "Loss: 1.324e-04\n",
            "Loss: 1.316e-04\n",
            "Loss: 1.310e-04\n",
            "Loss: 1.301e-04\n",
            "Loss: 1.291e-04\n",
            "Loss: 1.275e-04\n",
            "Loss: 1.264e-04\n",
            "Loss: 1.253e-04\n",
            "Loss: 1.241e-04\n",
            "Loss: 1.244e-04\n",
            "Loss: 1.233e-04\n",
            "Loss: 1.224e-04\n",
            "Loss: 1.219e-04\n",
            "Loss: 1.212e-04\n",
            "Loss: 1.201e-04\n",
            "Loss: 1.191e-04\n",
            "Loss: 1.174e-04\n",
            "Loss: 1.164e-04\n",
            "Loss: 1.154e-04\n",
            "Loss: 1.143e-04\n",
            "Loss: 1.138e-04\n",
            "Loss: 1.133e-04\n",
            "Loss: 1.129e-04\n",
            "Loss: 1.127e-04\n",
            "Loss: 1.116e-04\n",
            "Loss: 1.109e-04\n",
            "Loss: 1.102e-04\n",
            "Loss: 1.095e-04\n",
            "Loss: 1.090e-04\n",
            "Loss: 1.083e-04\n",
            "Loss: 1.069e-04\n",
            "Loss: 1.058e-04\n",
            "Loss: 1.043e-04\n",
            "Loss: 1.031e-04\n",
            "Loss: 1.037e-04\n",
            "Loss: 1.025e-04\n",
            "Loss: 1.021e-04\n",
            "Loss: 1.018e-04\n",
            "Loss: 1.013e-04\n",
            "Loss: 1.005e-04\n",
            "Loss: 9.909e-05\n",
            "Loss: 9.717e-05\n",
            "Loss: 9.564e-05\n",
            "Loss: 9.409e-05\n",
            "Loss: 9.313e-05\n",
            "Loss: 9.238e-05\n",
            "Loss: 9.172e-05\n",
            "Loss: 9.104e-05\n",
            "Loss: 9.057e-05\n",
            "Loss: 9.022e-05\n",
            "Loss: 9.003e-05\n",
            "Loss: 8.985e-05\n",
            "Loss: 8.952e-05\n",
            "Loss: 8.923e-05\n",
            "Loss: 8.890e-05\n",
            "Loss: 8.861e-05\n",
            "Loss: 8.823e-05\n",
            "Loss: 8.764e-05\n",
            "Loss: 8.764e-05\n",
            "Loss: 8.737e-05\n",
            "Loss: 8.701e-05\n",
            "Loss: 8.681e-05\n",
            "Loss: 8.659e-05\n",
            "Loss: 8.627e-05\n",
            "Loss: 8.597e-05\n",
            "Loss: 8.563e-05\n",
            "Loss: 8.536e-05\n",
            "Loss: 8.504e-05\n",
            "Loss: 8.450e-05\n",
            "Loss: 8.381e-05\n",
            "Loss: 8.296e-05\n",
            "Loss: 8.217e-05\n",
            "Loss: 8.152e-05\n",
            "Loss: 8.080e-05\n",
            "Loss: 8.000e-05\n",
            "Loss: 8.182e-05\n",
            "Loss: 7.972e-05\n",
            "Loss: 7.917e-05\n",
            "Loss: 7.892e-05\n",
            "Loss: 7.870e-05\n",
            "Loss: 7.856e-05\n",
            "Loss: 7.841e-05\n",
            "Loss: 7.826e-05\n",
            "Loss: 7.804e-05\n",
            "Loss: 7.774e-05\n",
            "Loss: 7.733e-05\n",
            "Loss: 7.670e-05\n",
            "Loss: 7.644e-05\n",
            "Loss: 7.597e-05\n",
            "Loss: 7.555e-05\n",
            "Loss: 7.518e-05\n",
            "Loss: 7.478e-05\n",
            "Loss: 7.431e-05\n",
            "Loss: 7.390e-05\n",
            "Loss: 7.356e-05\n",
            "Loss: 7.308e-05\n",
            "Loss: 7.269e-05\n",
            "Loss: 7.198e-05\n",
            "Loss: 7.151e-05\n",
            "Loss: 7.100e-05\n",
            "Loss: 7.054e-05\n",
            "Loss: 7.014e-05\n",
            "Loss: 6.987e-05\n",
            "Loss: 6.932e-05\n",
            "Loss: 6.910e-05\n",
            "Loss: 6.885e-05\n",
            "Loss: 6.850e-05\n",
            "Loss: 6.794e-05\n",
            "Loss: 6.721e-05\n",
            "Loss: 6.719e-05\n",
            "Loss: 6.677e-05\n",
            "Loss: 6.636e-05\n",
            "Loss: 6.603e-05\n",
            "Loss: 6.554e-05\n",
            "Loss: 6.485e-05\n",
            "Loss: 6.379e-05\n",
            "Loss: 6.328e-05\n",
            "Loss: 6.289e-05\n",
            "Loss: 6.245e-05\n",
            "Loss: 6.185e-05\n",
            "Loss: 6.166e-05\n",
            "Loss: 6.156e-05\n",
            "Loss: 6.146e-05\n",
            "Loss: 6.139e-05\n",
            "Loss: 6.132e-05\n",
            "Loss: 6.128e-05\n",
            "Loss: 6.125e-05\n",
            "Loss: 6.119e-05\n",
            "Loss: 6.111e-05\n",
            "Loss: 6.097e-05\n",
            "Loss: 6.085e-05\n",
            "Loss: 6.074e-05\n",
            "Loss: 6.061e-05\n",
            "Loss: 6.050e-05\n",
            "Loss: 6.033e-05\n",
            "Loss: 6.018e-05\n",
            "Loss: 5.996e-05\n",
            "Loss: 5.981e-05\n",
            "Loss: 5.965e-05\n",
            "Loss: 5.955e-05\n",
            "Loss: 5.948e-05\n",
            "Loss: 5.936e-05\n",
            "Loss: 5.923e-05\n",
            "Loss: 5.913e-05\n",
            "Loss: 5.903e-05\n",
            "Loss: 5.892e-05\n",
            "Loss: 5.885e-05\n",
            "Loss: 5.875e-05\n",
            "Loss: 5.863e-05\n",
            "Loss: 5.847e-05\n",
            "Loss: 5.846e-05\n",
            "Loss: 5.836e-05\n",
            "Loss: 5.824e-05\n",
            "Loss: 5.812e-05\n",
            "Loss: 5.804e-05\n",
            "Loss: 5.795e-05\n",
            "Loss: 5.787e-05\n",
            "Loss: 5.780e-05\n",
            "Loss: 5.769e-05\n",
            "Loss: 5.754e-05\n",
            "Loss: 5.737e-05\n",
            "Loss: 5.724e-05\n",
            "Loss: 5.697e-05\n",
            "Loss: 5.678e-05\n",
            "Loss: 5.650e-05\n",
            "Loss: 5.631e-05\n",
            "Loss: 5.607e-05\n",
            "Loss: 5.581e-05\n",
            "Loss: 5.553e-05\n",
            "Loss: 5.531e-05\n",
            "Loss: 5.498e-05\n",
            "Loss: 5.464e-05\n",
            "Loss: 5.430e-05\n",
            "Loss: 5.371e-05\n",
            "Loss: 5.327e-05\n",
            "Loss: 5.287e-05\n",
            "Loss: 5.264e-05\n",
            "Loss: 5.238e-05\n",
            "Loss: 5.214e-05\n",
            "Loss: 5.193e-05\n",
            "Loss: 5.176e-05\n",
            "Loss: 5.164e-05\n",
            "Loss: 5.153e-05\n",
            "Loss: 5.141e-05\n",
            "Loss: 5.130e-05\n",
            "Loss: 5.123e-05\n",
            "Loss: 5.112e-05\n",
            "Loss: 5.106e-05\n",
            "Loss: 5.100e-05\n",
            "Loss: 5.094e-05\n",
            "Loss: 5.084e-05\n",
            "Loss: 5.075e-05\n",
            "Loss: 5.067e-05\n",
            "Loss: 5.062e-05\n",
            "Loss: 5.058e-05\n",
            "Loss: 5.056e-05\n",
            "Loss: 5.051e-05\n",
            "Loss: 5.046e-05\n",
            "Loss: 5.039e-05\n",
            "Loss: 5.032e-05\n",
            "Loss: 5.046e-05\n",
            "Loss: 5.026e-05\n",
            "Loss: 5.011e-05\n",
            "Loss: 4.986e-05\n",
            "Loss: 4.966e-05\n",
            "Loss: 4.997e-05\n",
            "Loss: 4.956e-05\n",
            "Loss: 4.937e-05\n",
            "Loss: 4.912e-05\n",
            "Loss: 4.871e-05\n",
            "Loss: 4.814e-05\n",
            "Loss: 4.893e-05\n",
            "Loss: 4.769e-05\n",
            "Loss: 4.686e-05\n",
            "Loss: 4.626e-05\n",
            "Loss: 4.628e-05\n",
            "Loss: 4.610e-05\n",
            "Loss: 4.604e-05\n",
            "Loss: 4.594e-05\n",
            "Loss: 4.579e-05\n",
            "Loss: 4.558e-05\n",
            "Loss: 4.540e-05\n",
            "Loss: 4.511e-05\n",
            "Loss: 4.489e-05\n",
            "Loss: 4.469e-05\n",
            "Loss: 4.444e-05\n",
            "Loss: 4.439e-05\n",
            "Loss: 4.417e-05\n",
            "Loss: 4.408e-05\n",
            "Loss: 4.394e-05\n",
            "Loss: 4.363e-05\n",
            "Loss: 4.384e-05\n",
            "Loss: 4.351e-05\n",
            "Loss: 4.339e-05\n",
            "Loss: 4.330e-05\n",
            "Loss: 4.319e-05\n",
            "Loss: 4.302e-05\n",
            "Loss: 4.300e-05\n",
            "Loss: 4.268e-05\n",
            "Loss: 4.257e-05\n",
            "Loss: 4.237e-05\n",
            "Loss: 4.219e-05\n",
            "Loss: 4.203e-05\n",
            "Loss: 4.180e-05\n",
            "Loss: 4.179e-05\n",
            "Loss: 4.165e-05\n",
            "Loss: 4.159e-05\n",
            "Loss: 4.152e-05\n",
            "Loss: 4.143e-05\n",
            "Loss: 4.127e-05\n",
            "Loss: 4.123e-05\n",
            "Loss: 4.099e-05\n",
            "Loss: 4.083e-05\n",
            "Loss: 4.060e-05\n",
            "Loss: 4.027e-05\n",
            "Loss: 3.966e-05\n",
            "Loss: 4.015e-05\n",
            "Loss: 3.936e-05\n",
            "Loss: 3.875e-05\n",
            "Loss: 3.835e-05\n",
            "Loss: 3.824e-05\n",
            "Loss: 3.813e-05\n",
            "Loss: 3.807e-05\n",
            "Loss: 3.798e-05\n",
            "Loss: 3.790e-05\n",
            "Loss: 3.784e-05\n",
            "Loss: 3.779e-05\n",
            "Loss: 3.776e-05\n",
            "Loss: 3.772e-05\n",
            "Loss: 3.766e-05\n",
            "Loss: 3.759e-05\n",
            "Loss: 3.748e-05\n",
            "Loss: 3.741e-05\n",
            "Loss: 3.731e-05\n",
            "Loss: 3.723e-05\n",
            "Loss: 3.717e-05\n",
            "Loss: 3.702e-05\n",
            "Loss: 3.695e-05\n",
            "Loss: 3.686e-05\n",
            "Loss: 3.678e-05\n",
            "Loss: 3.669e-05\n",
            "Loss: 3.664e-05\n",
            "Loss: 3.660e-05\n",
            "Loss: 3.658e-05\n",
            "Loss: 3.655e-05\n",
            "Loss: 3.653e-05\n",
            "Loss: 3.649e-05\n",
            "Loss: 3.644e-05\n",
            "Loss: 3.641e-05\n",
            "Loss: 3.639e-05\n",
            "Loss: 3.637e-05\n",
            "Loss: 3.632e-05\n",
            "Loss: 3.627e-05\n",
            "Loss: 3.621e-05\n",
            "Loss: 3.615e-05\n",
            "Loss: 3.607e-05\n",
            "Loss: 3.600e-05\n",
            "Loss: 3.585e-05\n",
            "Loss: 3.608e-05\n",
            "Loss: 3.579e-05\n",
            "Loss: 3.570e-05\n",
            "Loss: 3.552e-05\n",
            "Loss: 3.539e-05\n",
            "Loss: 3.519e-05\n",
            "Loss: 3.605e-05\n",
            "Loss: 3.512e-05\n",
            "Loss: 3.503e-05\n",
            "Loss: 3.496e-05\n",
            "Loss: 3.492e-05\n",
            "Loss: 3.488e-05\n",
            "Loss: 3.479e-05\n",
            "Loss: 3.475e-05\n",
            "Loss: 3.469e-05\n",
            "Loss: 3.466e-05\n",
            "Loss: 3.463e-05\n",
            "Loss: 3.459e-05\n",
            "Loss: 3.455e-05\n",
            "Loss: 3.449e-05\n",
            "Loss: 3.438e-05\n",
            "Loss: 3.422e-05\n",
            "Loss: 3.407e-05\n",
            "Loss: 3.382e-05\n",
            "Loss: 3.361e-05\n",
            "Loss: 3.349e-05\n",
            "Loss: 3.330e-05\n",
            "Loss: 3.306e-05\n",
            "Loss: 3.291e-05\n",
            "Loss: 3.274e-05\n",
            "Loss: 3.263e-05\n",
            "Loss: 3.251e-05\n",
            "Loss: 3.243e-05\n",
            "Loss: 3.233e-05\n",
            "Loss: 3.226e-05\n",
            "Loss: 3.219e-05\n",
            "Loss: 3.210e-05\n",
            "Loss: 3.190e-05\n",
            "Loss: 3.175e-05\n",
            "Loss: 3.157e-05\n",
            "Loss: 3.139e-05\n",
            "Loss: 3.121e-05\n",
            "Loss: 3.095e-05\n",
            "Loss: 3.076e-05\n",
            "Loss: 3.056e-05\n",
            "Loss: 3.045e-05\n",
            "Loss: 3.037e-05\n",
            "Loss: 3.030e-05\n",
            "Loss: 3.023e-05\n",
            "Loss: 3.014e-05\n",
            "Loss: 3.010e-05\n",
            "Loss: 3.004e-05\n",
            "Loss: 3.001e-05\n",
            "Loss: 2.999e-05\n",
            "Loss: 2.996e-05\n",
            "Loss: 2.994e-05\n",
            "Loss: 2.991e-05\n",
            "Loss: 2.989e-05\n",
            "Loss: 2.984e-05\n",
            "Loss: 2.982e-05\n",
            "Loss: 2.978e-05\n",
            "Loss: 2.975e-05\n",
            "Loss: 2.972e-05\n",
            "Loss: 2.967e-05\n",
            "Loss: 2.980e-05\n",
            "Loss: 2.966e-05\n",
            "Loss: 2.961e-05\n",
            "Loss: 2.957e-05\n",
            "Loss: 2.954e-05\n",
            "Loss: 2.951e-05\n",
            "Loss: 2.950e-05\n",
            "Loss: 2.948e-05\n",
            "Loss: 2.947e-05\n",
            "Loss: 2.945e-05\n",
            "Loss: 2.943e-05\n",
            "Loss: 2.939e-05\n",
            "Loss: 2.934e-05\n",
            "Loss: 2.930e-05\n",
            "Loss: 2.928e-05\n",
            "Loss: 2.924e-05\n",
            "Loss: 2.921e-05\n",
            "Loss: 2.918e-05\n",
            "Loss: 2.917e-05\n",
            "Loss: 2.914e-05\n",
            "Loss: 2.912e-05\n",
            "Loss: 2.909e-05\n",
            "Loss: 2.905e-05\n",
            "Loss: 2.899e-05\n",
            "Loss: 2.903e-05\n",
            "Loss: 2.895e-05\n",
            "Loss: 2.891e-05\n",
            "Loss: 2.888e-05\n",
            "Loss: 2.884e-05\n",
            "Loss: 2.876e-05\n",
            "Loss: 2.886e-05\n",
            "Loss: 2.872e-05\n",
            "Loss: 2.867e-05\n",
            "Loss: 2.864e-05\n",
            "Loss: 2.861e-05\n",
            "Loss: 2.858e-05\n",
            "Loss: 2.853e-05\n",
            "Loss: 2.846e-05\n",
            "Loss: 2.843e-05\n",
            "Loss: 2.840e-05\n",
            "Loss: 2.838e-05\n",
            "Loss: 2.835e-05\n",
            "Loss: 2.829e-05\n",
            "Loss: 2.824e-05\n",
            "Loss: 2.819e-05\n",
            "Loss: 2.810e-05\n",
            "Loss: 2.805e-05\n",
            "Loss: 2.794e-05\n",
            "Loss: 2.784e-05\n",
            "Loss: 2.770e-05\n",
            "Loss: 2.735e-05\n",
            "Loss: 2.700e-05\n",
            "Loss: 2.682e-05\n",
            "Loss: 2.665e-05\n",
            "Loss: 2.657e-05\n",
            "Loss: 2.650e-05\n",
            "Loss: 2.646e-05\n",
            "Loss: 2.638e-05\n",
            "Loss: 2.634e-05\n",
            "Loss: 2.628e-05\n",
            "Loss: 2.619e-05\n",
            "Loss: 2.609e-05\n",
            "Loss: 2.603e-05\n",
            "Loss: 2.598e-05\n",
            "Loss: 2.594e-05\n",
            "Loss: 2.597e-05\n",
            "Loss: 2.591e-05\n",
            "Loss: 2.587e-05\n",
            "Loss: 2.581e-05\n",
            "Loss: 2.577e-05\n",
            "Loss: 2.572e-05\n",
            "Loss: 2.563e-05\n",
            "Loss: 2.550e-05\n",
            "Loss: 2.538e-05\n",
            "Loss: 2.531e-05\n",
            "Loss: 2.525e-05\n",
            "Loss: 2.522e-05\n",
            "Loss: 2.514e-05\n",
            "Loss: 2.503e-05\n",
            "Loss: 2.491e-05\n",
            "Loss: 2.480e-05\n",
            "Loss: 2.471e-05\n",
            "Loss: 2.463e-05\n",
            "Loss: 2.456e-05\n",
            "Loss: 2.459e-05\n",
            "Loss: 2.452e-05\n",
            "Loss: 2.445e-05\n",
            "Loss: 2.439e-05\n",
            "Loss: 2.433e-05\n",
            "Loss: 2.430e-05\n",
            "Loss: 2.429e-05\n",
            "Loss: 2.427e-05\n",
            "Loss: 2.426e-05\n",
            "Loss: 2.422e-05\n",
            "Loss: 2.417e-05\n",
            "Loss: 2.411e-05\n",
            "Loss: 2.405e-05\n",
            "Loss: 2.400e-05\n",
            "Loss: 2.395e-05\n",
            "Loss: 2.389e-05\n",
            "Loss: 2.382e-05\n",
            "Loss: 2.373e-05\n",
            "Loss: 2.368e-05\n",
            "Loss: 2.365e-05\n",
            "Loss: 2.362e-05\n",
            "Loss: 2.355e-05\n",
            "Loss: 2.347e-05\n",
            "Loss: 2.338e-05\n",
            "Loss: 2.332e-05\n",
            "Loss: 2.327e-05\n",
            "Loss: 2.325e-05\n",
            "Loss: 2.322e-05\n",
            "Loss: 2.319e-05\n",
            "Loss: 2.316e-05\n",
            "Loss: 2.312e-05\n",
            "Loss: 2.306e-05\n",
            "Loss: 2.297e-05\n",
            "Loss: 2.282e-05\n",
            "Loss: 2.268e-05\n",
            "Loss: 2.256e-05\n",
            "Loss: 2.249e-05\n",
            "Loss: 2.247e-05\n",
            "Loss: 2.245e-05\n",
            "Loss: 2.244e-05\n",
            "Loss: 2.241e-05\n",
            "Loss: 2.237e-05\n",
            "Loss: 2.234e-05\n",
            "Loss: 2.231e-05\n",
            "Loss: 2.226e-05\n",
            "Loss: 2.222e-05\n",
            "Loss: 2.220e-05\n",
            "Loss: 2.206e-05\n",
            "Loss: 2.200e-05\n",
            "Loss: 2.188e-05\n",
            "Loss: 2.179e-05\n",
            "Loss: 2.170e-05\n",
            "Loss: 2.151e-05\n",
            "Loss: 2.145e-05\n",
            "Loss: 2.141e-05\n",
            "Loss: 2.136e-05\n",
            "Loss: 2.134e-05\n",
            "Loss: 2.131e-05\n",
            "Loss: 2.128e-05\n",
            "Loss: 2.123e-05\n",
            "Loss: 2.122e-05\n",
            "Loss: 2.119e-05\n",
            "Loss: 2.118e-05\n",
            "Loss: 2.116e-05\n",
            "Loss: 2.115e-05\n",
            "Loss: 2.112e-05\n",
            "Loss: 2.110e-05\n",
            "Loss: 2.107e-05\n",
            "Loss: 2.105e-05\n",
            "Loss: 2.102e-05\n",
            "Loss: 2.098e-05\n",
            "Loss: 2.095e-05\n",
            "Loss: 2.092e-05\n",
            "Loss: 2.086e-05\n",
            "Loss: 2.078e-05\n",
            "Loss: 2.070e-05\n",
            "Loss: 2.061e-05\n",
            "Loss: 2.053e-05\n",
            "Loss: 2.049e-05\n",
            "Loss: 2.045e-05\n",
            "Loss: 2.041e-05\n",
            "Loss: 2.039e-05\n",
            "Loss: 2.036e-05\n",
            "Loss: 2.031e-05\n",
            "Loss: 2.026e-05\n",
            "Loss: 2.020e-05\n",
            "Loss: 2.019e-05\n",
            "Loss: 2.011e-05\n",
            "Loss: 2.008e-05\n",
            "Loss: 2.001e-05\n",
            "Loss: 1.992e-05\n",
            "Loss: 1.978e-05\n",
            "Loss: 1.987e-05\n",
            "Loss: 1.971e-05\n",
            "Loss: 1.958e-05\n",
            "Loss: 1.948e-05\n",
            "Loss: 1.942e-05\n",
            "Loss: 1.937e-05\n",
            "Loss: 1.932e-05\n",
            "Loss: 1.927e-05\n",
            "Loss: 1.920e-05\n",
            "Loss: 1.912e-05\n",
            "Loss: 1.897e-05\n",
            "Loss: 1.948e-05\n",
            "Loss: 1.890e-05\n",
            "Loss: 1.872e-05\n",
            "Loss: 1.850e-05\n",
            "Loss: 1.826e-05\n",
            "Loss: 1.806e-05\n",
            "Loss: 1.792e-05\n",
            "Loss: 1.779e-05\n",
            "Loss: 1.770e-05\n",
            "Loss: 1.761e-05\n",
            "Loss: 1.745e-05\n",
            "Loss: 1.714e-05\n",
            "Loss: 1.681e-05\n",
            "Loss: 1.657e-05\n",
            "Loss: 1.648e-05\n",
            "Loss: 1.625e-05\n",
            "Loss: 1.616e-05\n",
            "Loss: 1.600e-05\n",
            "Loss: 1.592e-05\n",
            "Loss: 1.581e-05\n",
            "Loss: 1.573e-05\n",
            "Loss: 1.565e-05\n",
            "Loss: 1.556e-05\n",
            "Loss: 1.548e-05\n",
            "Loss: 1.545e-05\n",
            "Loss: 1.539e-05\n",
            "Loss: 1.530e-05\n",
            "Loss: 1.517e-05\n",
            "Loss: 1.514e-05\n",
            "Loss: 1.501e-05\n",
            "Loss: 1.494e-05\n",
            "Loss: 1.487e-05\n",
            "Loss: 1.476e-05\n",
            "Loss: 1.458e-05\n",
            "Loss: 1.436e-05\n",
            "Loss: 1.420e-05\n",
            "Loss: 1.410e-05\n",
            "Loss: 1.401e-05\n",
            "Loss: 1.391e-05\n",
            "Loss: 1.385e-05\n",
            "Loss: 1.380e-05\n",
            "Loss: 1.376e-05\n",
            "Loss: 1.371e-05\n",
            "Loss: 1.367e-05\n",
            "Loss: 1.362e-05\n",
            "Loss: 1.357e-05\n",
            "Loss: 1.351e-05\n",
            "Loss: 1.346e-05\n",
            "Loss: 1.340e-05\n",
            "Loss: 1.338e-05\n",
            "Loss: 1.328e-05\n",
            "Loss: 1.323e-05\n",
            "Loss: 1.316e-05\n",
            "Loss: 1.310e-05\n",
            "Loss: 1.305e-05\n",
            "Loss: 1.299e-05\n",
            "Loss: 1.289e-05\n",
            "Loss: 1.281e-05\n",
            "Loss: 1.278e-05\n",
            "Loss: 1.273e-05\n",
            "Loss: 1.270e-05\n",
            "Loss: 1.267e-05\n",
            "Loss: 1.264e-05\n",
            "Loss: 1.259e-05\n",
            "Loss: 1.257e-05\n",
            "Loss: 1.253e-05\n",
            "Loss: 1.251e-05\n",
            "Loss: 1.248e-05\n",
            "Loss: 1.244e-05\n",
            "Loss: 1.245e-05\n",
            "Loss: 1.240e-05\n",
            "Loss: 1.234e-05\n",
            "Loss: 1.228e-05\n",
            "Loss: 1.221e-05\n",
            "Loss: 1.214e-05\n",
            "Loss: 1.210e-05\n",
            "Loss: 1.203e-05\n",
            "Loss: 1.199e-05\n",
            "Loss: 1.195e-05\n",
            "Loss: 1.191e-05\n",
            "Loss: 1.185e-05\n",
            "Loss: 1.181e-05\n",
            "Loss: 1.178e-05\n",
            "Loss: 1.174e-05\n",
            "Loss: 1.169e-05\n",
            "Loss: 1.162e-05\n",
            "Loss: 1.159e-05\n",
            "Loss: 1.157e-05\n",
            "Loss: 1.155e-05\n",
            "Loss: 1.152e-05\n",
            "Loss: 1.147e-05\n",
            "Loss: 1.142e-05\n",
            "Loss: 1.136e-05\n",
            "Loss: 1.131e-05\n",
            "Loss: 1.128e-05\n",
            "Loss: 1.125e-05\n",
            "Loss: 1.122e-05\n",
            "Loss: 1.115e-05\n",
            "Loss: 1.109e-05\n",
            "Loss: 1.103e-05\n",
            "Loss: 1.098e-05\n",
            "Loss: 1.093e-05\n",
            "Loss: 1.090e-05\n",
            "Loss: 1.087e-05\n",
            "Loss: 1.084e-05\n",
            "Loss: 1.080e-05\n",
            "Loss: 1.077e-05\n",
            "Loss: 1.073e-05\n",
            "Loss: 1.070e-05\n",
            "Loss: 1.069e-05\n",
            "Loss: 1.067e-05\n",
            "Loss: 1.066e-05\n",
            "Loss: 1.066e-05\n",
            "Loss: 1.065e-05\n",
            "Loss: 1.063e-05\n",
            "Loss: 1.062e-05\n",
            "Loss: 1.061e-05\n",
            "Loss: 1.060e-05\n",
            "Loss: 1.059e-05\n",
            "Loss: 1.059e-05\n",
            "Loss: 1.057e-05\n",
            "Loss: 1.056e-05\n",
            "Loss: 1.054e-05\n",
            "Loss: 1.053e-05\n",
            "Loss: 1.051e-05\n",
            "Loss: 1.049e-05\n",
            "Loss: 1.047e-05\n",
            "Loss: 1.046e-05\n",
            "Loss: 1.044e-05\n",
            "Loss: 1.043e-05\n",
            "Loss: 1.042e-05\n",
            "Loss: 1.040e-05\n",
            "Loss: 1.039e-05\n",
            "Loss: 1.038e-05\n",
            "Loss: 1.037e-05\n",
            "Loss: 1.036e-05\n",
            "Loss: 1.034e-05\n",
            "Loss: 1.032e-05\n",
            "Loss: 1.034e-05\n",
            "Loss: 1.031e-05\n",
            "Loss: 1.029e-05\n",
            "Loss: 1.028e-05\n",
            "Loss: 1.027e-05\n",
            "Loss: 1.025e-05\n",
            "Loss: 1.023e-05\n",
            "Loss: 1.021e-05\n",
            "Loss: 1.019e-05\n",
            "Loss: 1.022e-05\n",
            "Loss: 1.018e-05\n",
            "Loss: 1.016e-05\n",
            "Loss: 1.014e-05\n",
            "Loss: 1.013e-05\n",
            "Loss: 1.012e-05\n",
            "Loss: 1.012e-05\n",
            "Loss: 1.011e-05\n",
            "Loss: 1.010e-05\n",
            "Loss: 1.009e-05\n",
            "Loss: 1.009e-05\n",
            "Loss: 1.008e-05\n",
            "Loss: 1.007e-05\n",
            "Loss: 1.006e-05\n",
            "Loss: 1.005e-05\n",
            "Loss: 1.004e-05\n",
            "Loss: 1.002e-05\n",
            "Loss: 1.001e-05\n",
            "Loss: 9.994e-06\n",
            "Loss: 9.977e-06\n",
            "Loss: 9.961e-06\n",
            "Loss: 9.942e-06\n",
            "Loss: 9.910e-06\n",
            "Loss: 9.882e-06\n",
            "Loss: 9.847e-06\n",
            "Loss: 9.810e-06\n",
            "Loss: 9.797e-06\n",
            "Loss: 9.754e-06\n",
            "Loss: 9.731e-06\n",
            "Loss: 9.709e-06\n",
            "Loss: 9.685e-06\n",
            "Loss: 9.654e-06\n",
            "Loss: 9.624e-06\n",
            "Loss: 9.582e-06\n",
            "Loss: 9.540e-06\n",
            "Loss: 9.520e-06\n",
            "Loss: 9.493e-06\n",
            "Loss: 9.483e-06\n",
            "Loss: 9.472e-06\n",
            "Loss: 9.445e-06\n",
            "Loss: 9.402e-06\n",
            "Loss: 9.344e-06\n",
            "Loss: 9.308e-06\n",
            "Loss: 9.253e-06\n",
            "Loss: 9.204e-06\n",
            "Loss: 9.170e-06\n",
            "Loss: 9.148e-06\n",
            "Loss: 9.128e-06\n",
            "Loss: 9.107e-06\n",
            "Loss: 9.092e-06\n",
            "Loss: 9.074e-06\n",
            "Loss: 9.061e-06\n",
            "Loss: 9.038e-06\n",
            "Loss: 8.982e-06\n",
            "Loss: 8.930e-06\n",
            "Loss: 8.872e-06\n",
            "Loss: 8.830e-06\n",
            "Loss: 8.790e-06\n",
            "Loss: 8.769e-06\n",
            "Loss: 8.745e-06\n",
            "Loss: 8.718e-06\n",
            "Loss: 8.710e-06\n",
            "Loss: 8.691e-06\n",
            "Loss: 8.675e-06\n",
            "Loss: 8.661e-06\n",
            "Loss: 8.648e-06\n",
            "Loss: 8.635e-06\n",
            "Loss: 8.619e-06\n",
            "Loss: 8.605e-06\n",
            "Loss: 8.596e-06\n",
            "Loss: 8.590e-06\n",
            "Loss: 8.577e-06\n",
            "Loss: 8.571e-06\n",
            "Loss: 8.559e-06\n",
            "Loss: 8.551e-06\n",
            "Loss: 8.543e-06\n",
            "Loss: 8.532e-06\n",
            "Loss: 8.517e-06\n",
            "Loss: 8.502e-06\n",
            "Loss: 8.483e-06\n",
            "Loss: 8.454e-06\n",
            "Loss: 8.436e-06\n",
            "Loss: 8.407e-06\n",
            "Loss: 8.386e-06\n",
            "Loss: 8.369e-06\n",
            "Loss: 8.346e-06\n",
            "Loss: 8.309e-06\n",
            "Loss: 8.254e-06\n",
            "Loss: 8.205e-06\n",
            "Loss: 8.183e-06\n",
            "Loss: 8.165e-06\n",
            "Loss: 8.148e-06\n",
            "Loss: 8.123e-06\n",
            "Loss: 8.107e-06\n",
            "Loss: 8.092e-06\n",
            "Loss: 8.074e-06\n",
            "Loss: 8.056e-06\n",
            "Loss: 8.038e-06\n",
            "Loss: 8.018e-06\n",
            "Loss: 8.012e-06\n",
            "Loss: 7.984e-06\n",
            "Loss: 7.977e-06\n",
            "Loss: 7.962e-06\n",
            "Loss: 7.947e-06\n",
            "Loss: 7.928e-06\n",
            "Loss: 7.910e-06\n",
            "Loss: 7.898e-06\n",
            "Loss: 7.886e-06\n",
            "Loss: 7.874e-06\n",
            "Loss: 7.850e-06\n",
            "Loss: 7.827e-06\n",
            "Loss: 7.793e-06\n",
            "Loss: 7.771e-06\n",
            "Loss: 7.753e-06\n",
            "Loss: 7.742e-06\n",
            "Loss: 7.734e-06\n",
            "Loss: 7.712e-06\n",
            "Loss: 7.694e-06\n",
            "Loss: 7.663e-06\n",
            "Loss: 7.644e-06\n",
            "Loss: 7.631e-06\n",
            "Loss: 7.616e-06\n",
            "Loss: 7.603e-06\n",
            "Loss: 7.584e-06\n",
            "Loss: 7.557e-06\n",
            "Loss: 7.521e-06\n",
            "Loss: 7.494e-06\n",
            "Loss: 7.467e-06\n",
            "Loss: 7.452e-06\n",
            "Loss: 7.444e-06\n",
            "Loss: 7.438e-06\n",
            "Loss: 7.430e-06\n",
            "Loss: 7.467e-06\n",
            "Loss: 7.424e-06\n",
            "Loss: 7.403e-06\n",
            "Loss: 7.365e-06\n",
            "Loss: 7.344e-06\n",
            "Loss: 7.326e-06\n",
            "Loss: 7.310e-06\n",
            "Loss: 7.292e-06\n",
            "Loss: 7.275e-06\n",
            "Loss: 7.259e-06\n",
            "Loss: 7.245e-06\n",
            "Loss: 7.220e-06\n",
            "Loss: 7.208e-06\n",
            "Loss: 7.184e-06\n",
            "Loss: 7.161e-06\n",
            "Loss: 7.141e-06\n",
            "Loss: 7.116e-06\n",
            "Loss: 7.085e-06\n",
            "Loss: 7.119e-06\n",
            "Loss: 7.079e-06\n",
            "Loss: 7.071e-06\n",
            "Loss: 7.066e-06\n",
            "Loss: 7.060e-06\n",
            "Loss: 7.051e-06\n",
            "Loss: 7.042e-06\n",
            "Loss: 7.037e-06\n",
            "Loss: 7.031e-06\n",
            "Loss: 7.029e-06\n",
            "Loss: 7.027e-06\n",
            "Loss: 7.025e-06\n",
            "Loss: 7.022e-06\n",
            "Loss: 7.020e-06\n",
            "Loss: 7.018e-06\n",
            "Loss: 7.016e-06\n",
            "Loss: 7.012e-06\n",
            "Loss: 7.008e-06\n",
            "Loss: 7.005e-06\n",
            "Loss: 7.003e-06\n",
            "Loss: 7.000e-06\n",
            "Loss: 6.999e-06\n",
            "Loss: 6.996e-06\n",
            "Loss: 6.994e-06\n",
            "Loss: 6.992e-06\n",
            "Loss: 6.990e-06\n",
            "Loss: 6.987e-06\n",
            "Loss: 6.985e-06\n",
            "Loss: 6.982e-06\n",
            "Loss: 6.978e-06\n",
            "Loss: 7.015e-06\n",
            "Loss: 6.975e-06\n",
            "Loss: 6.972e-06\n",
            "Loss: 6.968e-06\n",
            "Loss: 6.964e-06\n",
            "Loss: 6.961e-06\n",
            "Loss: 6.952e-06\n",
            "Loss: 6.945e-06\n",
            "Loss: 6.936e-06\n",
            "Loss: 6.955e-06\n",
            "Loss: 6.931e-06\n",
            "Loss: 6.920e-06\n",
            "Loss: 6.910e-06\n",
            "Loss: 6.906e-06\n",
            "Loss: 6.900e-06\n",
            "Loss: 6.897e-06\n",
            "Loss: 6.890e-06\n",
            "Loss: 6.885e-06\n",
            "Loss: 6.879e-06\n",
            "Loss: 6.874e-06\n",
            "Loss: 6.870e-06\n",
            "Loss: 6.861e-06\n",
            "Loss: 6.851e-06\n",
            "Loss: 6.840e-06\n",
            "Loss: 6.827e-06\n",
            "Loss: 6.816e-06\n",
            "Loss: 6.807e-06\n",
            "Loss: 6.797e-06\n",
            "Loss: 6.790e-06\n",
            "Loss: 6.783e-06\n",
            "Loss: 6.776e-06\n",
            "Loss: 6.765e-06\n",
            "Loss: 6.769e-06\n",
            "Loss: 6.758e-06\n",
            "Loss: 6.742e-06\n",
            "Loss: 6.731e-06\n",
            "Loss: 6.724e-06\n",
            "Loss: 6.724e-06\n",
            "Loss: 6.714e-06\n",
            "Loss: 6.709e-06\n",
            "Loss: 6.703e-06\n",
            "Loss: 6.696e-06\n",
            "Loss: 6.688e-06\n",
            "Loss: 6.678e-06\n",
            "Loss: 6.670e-06\n",
            "Loss: 6.664e-06\n",
            "Loss: 6.660e-06\n",
            "Loss: 6.658e-06\n",
            "Loss: 6.656e-06\n",
            "Loss: 6.653e-06\n",
            "Loss: 6.648e-06\n",
            "Loss: 6.640e-06\n",
            "Loss: 6.647e-06\n",
            "Loss: 6.634e-06\n",
            "Loss: 6.622e-06\n",
            "Loss: 6.604e-06\n",
            "Loss: 6.595e-06\n",
            "Loss: 6.585e-06\n",
            "Loss: 6.574e-06\n",
            "Loss: 6.564e-06\n",
            "Loss: 6.555e-06\n",
            "Loss: 6.546e-06\n",
            "Loss: 6.540e-06\n",
            "Loss: 6.535e-06\n",
            "Loss: 6.527e-06\n",
            "Loss: 6.521e-06\n",
            "Loss: 6.516e-06\n",
            "Loss: 6.510e-06\n",
            "Loss: 6.505e-06\n",
            "Loss: 6.500e-06\n",
            "Loss: 6.496e-06\n",
            "Loss: 6.492e-06\n",
            "Loss: 6.485e-06\n",
            "Loss: 6.478e-06\n",
            "Loss: 6.470e-06\n",
            "Loss: 6.464e-06\n",
            "Loss: 6.460e-06\n",
            "Loss: 6.454e-06\n",
            "Loss: 6.448e-06\n",
            "Loss: 6.443e-06\n",
            "Loss: 6.439e-06\n",
            "Loss: 6.432e-06\n",
            "Loss: 6.426e-06\n",
            "Loss: 6.419e-06\n",
            "Loss: 6.412e-06\n",
            "Loss: 6.408e-06\n",
            "Loss: 6.399e-06\n",
            "Loss: 6.392e-06\n",
            "Loss: 6.382e-06\n",
            "Loss: 6.371e-06\n",
            "Loss: 6.361e-06\n",
            "Loss: 6.356e-06\n",
            "Loss: 6.349e-06\n",
            "Loss: 6.343e-06\n",
            "Loss: 6.335e-06\n",
            "Loss: 6.326e-06\n",
            "Loss: 6.333e-06\n",
            "Loss: 6.322e-06\n",
            "Loss: 6.318e-06\n",
            "Loss: 6.314e-06\n",
            "Loss: 6.310e-06\n",
            "Loss: 6.307e-06\n",
            "Loss: 6.305e-06\n",
            "Loss: 6.304e-06\n",
            "Loss: 6.304e-06\n",
            "Loss: 6.302e-06\n",
            "Loss: 6.301e-06\n",
            "Loss: 6.297e-06\n",
            "Loss: 6.292e-06\n",
            "Loss: 6.285e-06\n",
            "Loss: 6.283e-06\n",
            "Loss: 6.268e-06\n",
            "Loss: 6.263e-06\n",
            "Loss: 6.255e-06\n",
            "Loss: 6.245e-06\n",
            "Loss: 6.232e-06\n",
            "Loss: 6.219e-06\n",
            "Loss: 6.206e-06\n",
            "Loss: 6.199e-06\n",
            "Loss: 6.181e-06\n",
            "Loss: 6.164e-06\n",
            "Loss: 6.149e-06\n",
            "Loss: 6.117e-06\n",
            "Loss: 6.100e-06\n",
            "Loss: 6.070e-06\n",
            "Loss: 6.056e-06\n",
            "Loss: 6.037e-06\n",
            "Loss: 6.024e-06\n",
            "Loss: 6.016e-06\n",
            "Loss: 6.010e-06\n",
            "Loss: 6.002e-06\n",
            "Loss: 5.991e-06\n",
            "Loss: 5.979e-06\n",
            "Loss: 5.970e-06\n",
            "Loss: 5.962e-06\n",
            "Loss: 5.951e-06\n",
            "Loss: 5.952e-06\n",
            "Loss: 5.943e-06\n",
            "Loss: 5.928e-06\n",
            "Loss: 5.920e-06\n",
            "Loss: 5.915e-06\n",
            "Loss: 5.914e-06\n",
            "Loss: 5.913e-06\n",
            "Loss: 5.909e-06\n",
            "Loss: 5.908e-06\n",
            "Loss: 5.905e-06\n",
            "Loss: 5.912e-06\n",
            "Loss: 5.904e-06\n",
            "Loss: 5.902e-06\n",
            "Loss: 5.901e-06\n",
            "Loss: 5.900e-06\n",
            "Loss: 5.900e-06\n",
            "Loss: 5.899e-06\n",
            "Loss: 5.897e-06\n",
            "Loss: 5.897e-06\n",
            "Loss: 5.895e-06\n",
            "Loss: 5.893e-06\n",
            "Loss: 5.890e-06\n",
            "Loss: 5.887e-06\n",
            "Loss: 5.883e-06\n",
            "Loss: 5.880e-06\n",
            "Loss: 5.878e-06\n",
            "Loss: 5.875e-06\n",
            "Loss: 5.870e-06\n",
            "Loss: 5.864e-06\n",
            "Loss: 5.862e-06\n",
            "Loss: 5.859e-06\n",
            "Loss: 5.857e-06\n",
            "Loss: 5.855e-06\n",
            "Loss: 5.852e-06\n",
            "Loss: 5.848e-06\n",
            "Loss: 5.845e-06\n",
            "Loss: 5.841e-06\n",
            "Loss: 5.835e-06\n",
            "Loss: 5.831e-06\n",
            "Loss: 5.827e-06\n",
            "Loss: 5.825e-06\n",
            "Loss: 5.818e-06\n",
            "Loss: 5.826e-06\n",
            "Loss: 5.816e-06\n",
            "Loss: 5.812e-06\n",
            "Loss: 5.807e-06\n",
            "Loss: 5.804e-06\n",
            "Loss: 5.799e-06\n",
            "Loss: 5.794e-06\n",
            "Loss: 5.784e-06\n",
            "Loss: 5.778e-06\n",
            "Loss: 5.768e-06\n",
            "Loss: 5.767e-06\n",
            "Loss: 5.756e-06\n",
            "Loss: 5.751e-06\n",
            "Loss: 5.743e-06\n",
            "Loss: 5.736e-06\n",
            "Loss: 5.744e-06\n",
            "Loss: 5.733e-06\n",
            "Loss: 5.728e-06\n",
            "Loss: 5.727e-06\n",
            "Loss: 5.721e-06\n",
            "Loss: 5.718e-06\n",
            "Loss: 5.714e-06\n",
            "Loss: 5.708e-06\n",
            "Loss: 5.702e-06\n",
            "Loss: 5.722e-06\n",
            "Loss: 5.699e-06\n",
            "Loss: 5.692e-06\n",
            "Loss: 5.685e-06\n",
            "Loss: 5.679e-06\n",
            "Loss: 5.668e-06\n",
            "Loss: 5.859e-06\n",
            "Loss: 5.665e-06\n",
            "Loss: 5.651e-06\n",
            "Loss: 5.637e-06\n",
            "Loss: 5.618e-06\n",
            "Loss: 5.600e-06\n",
            "Loss: 5.585e-06\n",
            "Loss: 5.570e-06\n",
            "Loss: 5.550e-06\n",
            "Loss: 5.512e-06\n",
            "Loss: 5.501e-06\n",
            "Loss: 5.479e-06\n",
            "Loss: 5.466e-06\n",
            "Loss: 5.446e-06\n",
            "Loss: 5.432e-06\n",
            "Loss: 5.417e-06\n",
            "Loss: 5.405e-06\n",
            "Loss: 5.387e-06\n",
            "Loss: 5.361e-06\n",
            "Loss: 5.314e-06\n",
            "Loss: 5.269e-06\n",
            "Loss: 5.239e-06\n",
            "Loss: 5.203e-06\n",
            "Loss: 5.179e-06\n",
            "Loss: 5.148e-06\n",
            "Loss: 5.130e-06\n",
            "Loss: 5.095e-06\n",
            "Loss: 5.089e-06\n",
            "Loss: 5.060e-06\n",
            "Loss: 5.048e-06\n",
            "Loss: 5.036e-06\n",
            "Loss: 5.022e-06\n",
            "Loss: 5.008e-06\n",
            "Loss: 4.990e-06\n",
            "Loss: 4.975e-06\n",
            "Loss: 4.962e-06\n",
            "Loss: 4.952e-06\n",
            "Loss: 4.943e-06\n",
            "Loss: 4.934e-06\n",
            "Loss: 4.920e-06\n",
            "Loss: 4.909e-06\n",
            "Loss: 4.909e-06\n",
            "Loss: 4.898e-06\n",
            "Loss: 4.890e-06\n",
            "Loss: 4.885e-06\n",
            "Loss: 4.881e-06\n",
            "Loss: 4.879e-06\n",
            "Loss: 4.871e-06\n",
            "Loss: 4.865e-06\n",
            "Loss: 4.860e-06\n",
            "Loss: 4.855e-06\n",
            "Loss: 4.850e-06\n",
            "Loss: 4.846e-06\n",
            "Loss: 4.840e-06\n",
            "Loss: 4.834e-06\n",
            "Loss: 4.826e-06\n",
            "Loss: 4.798e-06\n",
            "Loss: 4.770e-06\n",
            "Loss: 4.741e-06\n",
            "Loss: 4.712e-06\n",
            "Loss: 4.700e-06\n",
            "Loss: 4.678e-06\n",
            "Loss: 4.667e-06\n",
            "Loss: 4.652e-06\n",
            "Loss: 4.632e-06\n",
            "Loss: 4.606e-06\n",
            "Loss: 4.627e-06\n",
            "Loss: 4.593e-06\n",
            "Loss: 4.578e-06\n",
            "Loss: 4.582e-06\n",
            "Loss: 4.568e-06\n",
            "Loss: 4.554e-06\n",
            "Loss: 4.538e-06\n",
            "Loss: 4.516e-06\n",
            "Loss: 4.496e-06\n",
            "Loss: 4.478e-06\n",
            "Loss: 4.461e-06\n",
            "Loss: 4.444e-06\n",
            "Loss: 4.432e-06\n",
            "Loss: 4.428e-06\n",
            "Loss: 4.424e-06\n",
            "Loss: 4.417e-06\n",
            "Loss: 4.409e-06\n",
            "Loss: 4.402e-06\n",
            "Loss: 4.398e-06\n",
            "Loss: 4.395e-06\n",
            "Loss: 4.389e-06\n",
            "Loss: 4.384e-06\n",
            "Loss: 4.383e-06\n",
            "Loss: 4.380e-06\n",
            "Loss: 4.379e-06\n",
            "Loss: 4.376e-06\n",
            "Loss: 4.372e-06\n",
            "Loss: 4.365e-06\n",
            "Loss: 4.364e-06\n",
            "Loss: 4.361e-06\n",
            "Loss: 4.355e-06\n",
            "Loss: 4.351e-06\n",
            "Loss: 4.348e-06\n",
            "Loss: 4.339e-06\n",
            "Loss: 4.356e-06\n",
            "Loss: 4.336e-06\n",
            "Loss: 4.327e-06\n",
            "Loss: 4.325e-06\n",
            "Loss: 4.313e-06\n",
            "Loss: 4.307e-06\n",
            "Loss: 4.295e-06\n",
            "Loss: 4.287e-06\n",
            "Loss: 4.280e-06\n",
            "Loss: 4.274e-06\n",
            "Loss: 4.267e-06\n",
            "Loss: 4.260e-06\n",
            "Loss: 4.253e-06\n",
            "Loss: 4.248e-06\n",
            "Loss: 4.241e-06\n",
            "Loss: 4.235e-06\n",
            "Loss: 4.229e-06\n",
            "Loss: 4.225e-06\n",
            "Loss: 4.222e-06\n",
            "Loss: 4.219e-06\n",
            "Loss: 4.216e-06\n",
            "Loss: 4.213e-06\n",
            "Loss: 4.207e-06\n",
            "Loss: 4.199e-06\n",
            "Loss: 4.192e-06\n",
            "Loss: 4.183e-06\n",
            "Loss: 4.177e-06\n",
            "Loss: 4.173e-06\n",
            "Loss: 4.168e-06\n",
            "Loss: 4.160e-06\n",
            "Loss: 4.151e-06\n",
            "Loss: 4.140e-06\n",
            "Loss: 4.191e-06\n",
            "Loss: 4.138e-06\n",
            "Loss: 4.132e-06\n",
            "Loss: 4.129e-06\n",
            "Loss: 4.126e-06\n",
            "Loss: 4.124e-06\n",
            "Loss: 4.122e-06\n",
            "Loss: 4.120e-06\n",
            "Loss: 4.118e-06\n",
            "Loss: 4.116e-06\n",
            "Loss: 4.112e-06\n",
            "Loss: 4.106e-06\n",
            "Loss: 4.110e-06\n",
            "Loss: 4.102e-06\n",
            "Loss: 4.097e-06\n",
            "Loss: 4.095e-06\n",
            "Loss: 4.092e-06\n",
            "Loss: 4.089e-06\n",
            "Loss: 4.086e-06\n",
            "Loss: 4.083e-06\n",
            "Loss: 4.080e-06\n",
            "Loss: 4.077e-06\n",
            "Loss: 4.072e-06\n",
            "Loss: 4.068e-06\n",
            "Loss: 4.064e-06\n",
            "Loss: 4.062e-06\n",
            "Loss: 4.058e-06\n",
            "Loss: 4.057e-06\n",
            "Loss: 4.054e-06\n",
            "Loss: 4.053e-06\n",
            "Loss: 4.052e-06\n",
            "Loss: 4.051e-06\n",
            "Loss: 4.049e-06\n",
            "Loss: 4.047e-06\n",
            "Loss: 4.046e-06\n",
            "Loss: 4.044e-06\n",
            "Loss: 4.042e-06\n",
            "Loss: 4.039e-06\n",
            "Loss: 4.037e-06\n",
            "Loss: 4.034e-06\n",
            "Loss: 4.030e-06\n",
            "Loss: 4.033e-06\n",
            "Loss: 4.027e-06\n",
            "Loss: 4.026e-06\n",
            "Loss: 4.022e-06\n",
            "Loss: 4.020e-06\n",
            "Loss: 4.017e-06\n",
            "Loss: 4.012e-06\n",
            "Loss: 4.044e-06\n",
            "Loss: 4.010e-06\n",
            "Loss: 4.005e-06\n",
            "Loss: 4.001e-06\n",
            "Loss: 3.998e-06\n",
            "Loss: 3.996e-06\n",
            "Loss: 3.994e-06\n",
            "Loss: 3.993e-06\n",
            "Loss: 3.990e-06\n",
            "Loss: 3.988e-06\n",
            "Loss: 3.986e-06\n",
            "Loss: 3.984e-06\n",
            "Loss: 3.982e-06\n",
            "Loss: 3.980e-06\n",
            "Loss: 3.978e-06\n",
            "Loss: 3.974e-06\n",
            "Loss: 3.971e-06\n",
            "Loss: 3.966e-06\n",
            "Loss: 3.964e-06\n",
            "Loss: 3.961e-06\n",
            "Loss: 3.954e-06\n",
            "Loss: 3.948e-06\n",
            "Loss: 3.941e-06\n",
            "Loss: 3.928e-06\n",
            "Loss: 3.915e-06\n",
            "Loss: 3.921e-06\n",
            "Loss: 3.909e-06\n",
            "Loss: 3.901e-06\n",
            "Loss: 3.896e-06\n",
            "Loss: 3.893e-06\n",
            "Loss: 3.890e-06\n",
            "Loss: 3.884e-06\n",
            "Loss: 3.880e-06\n",
            "Loss: 3.872e-06\n",
            "Loss: 3.867e-06\n",
            "Loss: 3.863e-06\n",
            "Loss: 3.858e-06\n",
            "Loss: 3.855e-06\n",
            "Loss: 3.847e-06\n",
            "Loss: 3.843e-06\n",
            "Loss: 3.838e-06\n",
            "Loss: 3.836e-06\n",
            "Loss: 3.833e-06\n",
            "Loss: 3.830e-06\n",
            "Loss: 3.827e-06\n",
            "Loss: 3.825e-06\n",
            "Loss: 3.824e-06\n",
            "Loss: 3.822e-06\n",
            "Loss: 3.818e-06\n",
            "Loss: 3.813e-06\n",
            "Loss: 3.809e-06\n",
            "Loss: 3.805e-06\n",
            "Loss: 3.801e-06\n",
            "Loss: 3.796e-06\n",
            "Loss: 3.792e-06\n",
            "Loss: 3.790e-06\n",
            "Loss: 3.788e-06\n",
            "Loss: 3.785e-06\n",
            "Loss: 3.781e-06\n",
            "Loss: 3.776e-06\n",
            "Loss: 3.770e-06\n",
            "Loss: 3.764e-06\n",
            "Loss: 3.790e-06\n",
            "Loss: 3.763e-06\n",
            "Loss: 3.761e-06\n",
            "Loss: 3.756e-06\n",
            "Loss: 3.752e-06\n",
            "Loss: 3.747e-06\n",
            "Loss: 3.744e-06\n",
            "Loss: 3.742e-06\n",
            "Loss: 3.740e-06\n",
            "Loss: 3.739e-06\n",
            "Loss: 3.737e-06\n",
            "Loss: 3.735e-06\n",
            "Loss: 3.733e-06\n",
            "Loss: 3.730e-06\n",
            "Loss: 3.728e-06\n",
            "Loss: 3.727e-06\n",
            "Loss: 3.725e-06\n",
            "Loss: 3.723e-06\n",
            "Loss: 3.720e-06\n",
            "Loss: 3.717e-06\n",
            "Loss: 3.715e-06\n",
            "Loss: 3.716e-06\n",
            "Loss: 3.714e-06\n",
            "Loss: 3.712e-06\n",
            "Loss: 3.707e-06\n",
            "Loss: 3.703e-06\n",
            "Loss: 3.697e-06\n",
            "Loss: 3.689e-06\n",
            "Loss: 3.680e-06\n",
            "Loss: 3.674e-06\n",
            "Loss: 3.662e-06\n",
            "Loss: 3.657e-06\n",
            "Loss: 3.652e-06\n",
            "Loss: 3.641e-06\n",
            "Loss: 3.629e-06\n",
            "Loss: 3.616e-06\n",
            "Loss: 3.601e-06\n",
            "Loss: 3.591e-06\n",
            "Loss: 3.585e-06\n",
            "Loss: 3.581e-06\n",
            "Loss: 3.577e-06\n",
            "Loss: 3.574e-06\n",
            "Loss: 3.572e-06\n",
            "Loss: 3.569e-06\n",
            "Loss: 3.566e-06\n",
            "Loss: 3.563e-06\n",
            "Loss: 3.558e-06\n",
            "Loss: 3.551e-06\n",
            "Loss: 3.553e-06\n",
            "Loss: 3.546e-06\n",
            "Loss: 3.535e-06\n",
            "Loss: 3.526e-06\n",
            "Loss: 3.513e-06\n",
            "Loss: 3.529e-06\n",
            "Loss: 3.506e-06\n",
            "Loss: 3.495e-06\n",
            "Loss: 3.483e-06\n",
            "Loss: 3.473e-06\n",
            "Loss: 3.469e-06\n",
            "Loss: 3.463e-06\n",
            "Loss: 3.459e-06\n",
            "Loss: 3.453e-06\n",
            "Loss: 3.444e-06\n",
            "Loss: 3.433e-06\n",
            "Loss: 3.427e-06\n",
            "Loss: 3.421e-06\n",
            "Loss: 3.413e-06\n",
            "Loss: 3.565e-06\n",
            "Loss: 3.410e-06\n",
            "Loss: 3.404e-06\n",
            "Loss: 3.397e-06\n",
            "Loss: 3.392e-06\n",
            "Loss: 3.384e-06\n",
            "Loss: 3.375e-06\n",
            "Loss: 3.371e-06\n",
            "Loss: 3.365e-06\n",
            "Loss: 3.362e-06\n",
            "Loss: 3.354e-06\n",
            "Loss: 3.349e-06\n",
            "Loss: 3.343e-06\n",
            "Loss: 3.339e-06\n",
            "Loss: 3.335e-06\n",
            "Loss: 3.331e-06\n",
            "Loss: 3.327e-06\n",
            "Loss: 3.324e-06\n",
            "Loss: 3.322e-06\n",
            "Loss: 3.318e-06\n",
            "Loss: 3.314e-06\n",
            "Loss: 3.311e-06\n",
            "Loss: 3.306e-06\n",
            "Loss: 3.304e-06\n",
            "Loss: 3.299e-06\n",
            "Loss: 3.297e-06\n",
            "Loss: 3.295e-06\n",
            "Loss: 3.293e-06\n",
            "Loss: 3.289e-06\n",
            "Loss: 3.283e-06\n",
            "Loss: 3.287e-06\n",
            "Loss: 3.281e-06\n",
            "Loss: 3.276e-06\n",
            "Loss: 3.272e-06\n",
            "Loss: 3.267e-06\n",
            "Loss: 3.262e-06\n",
            "Loss: 3.258e-06\n",
            "Loss: 3.253e-06\n",
            "Loss: 3.244e-06\n",
            "Loss: 3.237e-06\n",
            "Loss: 3.228e-06\n",
            "Loss: 3.222e-06\n",
            "Loss: 3.217e-06\n",
            "Loss: 3.220e-06\n",
            "Loss: 3.215e-06\n",
            "Loss: 3.210e-06\n",
            "Loss: 3.208e-06\n",
            "Loss: 3.205e-06\n",
            "Loss: 3.202e-06\n",
            "Loss: 3.199e-06\n",
            "Loss: 3.197e-06\n",
            "Loss: 3.193e-06\n",
            "Loss: 3.191e-06\n",
            "Loss: 3.188e-06\n",
            "Loss: 3.184e-06\n",
            "Loss: 3.181e-06\n",
            "Loss: 3.179e-06\n",
            "Loss: 3.176e-06\n",
            "Loss: 3.174e-06\n",
            "Loss: 3.171e-06\n",
            "Loss: 3.167e-06\n",
            "Loss: 3.162e-06\n",
            "Loss: 3.157e-06\n",
            "Loss: 3.164e-06\n",
            "Loss: 3.154e-06\n",
            "Loss: 3.150e-06\n",
            "Loss: 3.147e-06\n",
            "Loss: 3.146e-06\n",
            "Loss: 3.144e-06\n",
            "Loss: 3.142e-06\n",
            "Loss: 3.142e-06\n",
            "Loss: 3.141e-06\n",
            "Loss: 3.140e-06\n",
            "Loss: 3.137e-06\n",
            "Loss: 3.136e-06\n",
            "Loss: 3.134e-06\n",
            "Loss: 3.134e-06\n",
            "Loss: 3.131e-06\n",
            "Loss: 3.130e-06\n",
            "Loss: 3.127e-06\n",
            "Loss: 3.125e-06\n",
            "Loss: 3.127e-06\n",
            "Loss: 3.124e-06\n",
            "Loss: 3.122e-06\n",
            "Loss: 3.121e-06\n",
            "Loss: 3.121e-06\n",
            "Loss: 3.120e-06\n",
            "Loss: 3.119e-06\n",
            "Loss: 3.117e-06\n",
            "Loss: 3.114e-06\n",
            "Loss: 3.111e-06\n",
            "Loss: 3.108e-06\n",
            "Loss: 3.104e-06\n",
            "Loss: 3.100e-06\n",
            "Loss: 3.096e-06\n",
            "Loss: 3.091e-06\n",
            "Loss: 3.087e-06\n",
            "Loss: 3.081e-06\n",
            "Loss: 3.078e-06\n",
            "Loss: 3.073e-06\n",
            "Loss: 3.070e-06\n",
            "Loss: 3.067e-06\n",
            "Loss: 3.065e-06\n",
            "Loss: 3.063e-06\n",
            "Loss: 3.077e-06\n",
            "Loss: 3.061e-06\n",
            "Loss: 3.059e-06\n",
            "Loss: 3.057e-06\n",
            "Loss: 3.057e-06\n",
            "Loss: 3.055e-06\n",
            "Loss: 3.054e-06\n",
            "Loss: 3.054e-06\n",
            "Loss: 3.052e-06\n",
            "Loss: 3.051e-06\n",
            "Loss: 3.050e-06\n",
            "Loss: 3.048e-06\n",
            "Loss: 3.047e-06\n",
            "Loss: 3.046e-06\n",
            "Loss: 3.045e-06\n",
            "Loss: 3.043e-06\n",
            "Loss: 3.040e-06\n",
            "Loss: 3.038e-06\n",
            "Loss: 3.036e-06\n",
            "Loss: 3.033e-06\n",
            "Loss: 3.033e-06\n",
            "Loss: 3.029e-06\n",
            "Loss: 3.026e-06\n",
            "Loss: 3.024e-06\n",
            "Loss: 3.024e-06\n",
            "Loss: 3.023e-06\n",
            "Loss: 3.023e-06\n",
            "Loss: 3.022e-06\n",
            "Loss: 3.021e-06\n",
            "Loss: 3.020e-06\n",
            "Loss: 3.020e-06\n",
            "Loss: 3.019e-06\n",
            "Loss: 3.019e-06\n",
            "Loss: 3.019e-06\n",
            "Loss: 3.018e-06\n",
            "Loss: 3.017e-06\n",
            "Loss: 3.017e-06\n",
            "Loss: 3.015e-06\n",
            "Loss: 3.011e-06\n",
            "Loss: 3.007e-06\n",
            "Loss: 3.003e-06\n",
            "Loss: 2.997e-06\n",
            "Loss: 2.993e-06\n",
            "Loss: 2.990e-06\n",
            "Loss: 2.988e-06\n",
            "Loss: 2.986e-06\n",
            "Loss: 2.983e-06\n",
            "Loss: 2.981e-06\n",
            "Loss: 2.980e-06\n",
            "Loss: 2.977e-06\n",
            "Loss: 2.976e-06\n",
            "Loss: 2.974e-06\n",
            "Loss: 2.972e-06\n",
            "Loss: 2.970e-06\n",
            "Loss: 2.969e-06\n",
            "Loss: 2.967e-06\n",
            "Loss: 2.965e-06\n",
            "Loss: 2.964e-06\n",
            "Loss: 2.964e-06\n",
            "Loss: 2.963e-06\n",
            "Loss: 2.962e-06\n",
            "Loss: 2.961e-06\n",
            "Loss: 2.959e-06\n",
            "Loss: 2.957e-06\n",
            "Loss: 2.955e-06\n",
            "Loss: 2.953e-06\n",
            "Loss: 2.952e-06\n",
            "Loss: 2.950e-06\n",
            "Loss: 2.948e-06\n",
            "Loss: 2.946e-06\n",
            "Loss: 2.946e-06\n",
            "Loss: 2.945e-06\n",
            "Loss: 2.944e-06\n",
            "Loss: 2.943e-06\n",
            "Loss: 2.942e-06\n",
            "Loss: 2.941e-06\n",
            "Loss: 2.940e-06\n",
            "Loss: 2.946e-06\n",
            "Loss: 2.939e-06\n",
            "Loss: 2.938e-06\n",
            "Loss: 2.935e-06\n",
            "Loss: 2.934e-06\n",
            "Loss: 2.933e-06\n",
            "Loss: 2.933e-06\n",
            "Loss: 2.931e-06\n",
            "Loss: 2.930e-06\n",
            "Loss: 2.928e-06\n",
            "Loss: 2.923e-06\n",
            "Loss: 2.920e-06\n",
            "Loss: 2.919e-06\n",
            "Loss: 2.916e-06\n",
            "Loss: 2.910e-06\n",
            "Loss: 2.905e-06\n",
            "Loss: 2.899e-06\n",
            "Loss: 2.895e-06\n",
            "Loss: 2.892e-06\n",
            "Loss: 2.889e-06\n",
            "Loss: 2.885e-06\n",
            "Loss: 2.881e-06\n",
            "Loss: 2.877e-06\n",
            "Loss: 2.874e-06\n",
            "Loss: 2.873e-06\n",
            "Loss: 2.871e-06\n",
            "Loss: 2.868e-06\n",
            "Loss: 2.865e-06\n",
            "Loss: 2.858e-06\n",
            "Loss: 2.854e-06\n",
            "Loss: 2.849e-06\n",
            "Loss: 2.844e-06\n",
            "Loss: 2.841e-06\n",
            "Loss: 2.837e-06\n",
            "Loss: 2.833e-06\n",
            "Loss: 2.830e-06\n",
            "Loss: 2.824e-06\n",
            "Loss: 2.823e-06\n",
            "Loss: 2.819e-06\n",
            "Loss: 2.816e-06\n",
            "Loss: 2.813e-06\n",
            "Loss: 2.810e-06\n",
            "Loss: 2.804e-06\n",
            "Loss: 2.798e-06\n",
            "Loss: 2.793e-06\n",
            "Loss: 2.785e-06\n",
            "Loss: 2.782e-06\n",
            "Loss: 2.777e-06\n",
            "Loss: 2.774e-06\n",
            "Loss: 2.771e-06\n",
            "Loss: 2.767e-06\n",
            "Loss: 2.764e-06\n",
            "Loss: 2.759e-06\n",
            "Loss: 2.754e-06\n",
            "Loss: 2.748e-06\n",
            "Loss: 2.740e-06\n",
            "Loss: 2.733e-06\n",
            "Loss: 2.727e-06\n",
            "Loss: 2.725e-06\n",
            "Loss: 2.713e-06\n",
            "Loss: 2.709e-06\n",
            "Loss: 2.703e-06\n",
            "Loss: 2.699e-06\n",
            "Loss: 2.693e-06\n",
            "Loss: 2.721e-06\n",
            "Loss: 2.692e-06\n",
            "Loss: 2.689e-06\n",
            "Loss: 2.686e-06\n",
            "Loss: 2.685e-06\n",
            "Loss: 2.682e-06\n",
            "Loss: 2.680e-06\n",
            "Loss: 2.678e-06\n",
            "Loss: 2.676e-06\n",
            "Loss: 2.671e-06\n",
            "Loss: 2.667e-06\n",
            "Loss: 2.663e-06\n",
            "Loss: 2.660e-06\n",
            "Loss: 2.661e-06\n",
            "Loss: 2.658e-06\n",
            "Loss: 2.657e-06\n",
            "Loss: 2.654e-06\n",
            "Loss: 2.650e-06\n",
            "Loss: 2.654e-06\n",
            "Loss: 2.648e-06\n",
            "Loss: 2.645e-06\n",
            "Loss: 2.642e-06\n",
            "Loss: 2.638e-06\n",
            "Loss: 2.632e-06\n",
            "Loss: 2.637e-06\n",
            "Loss: 2.630e-06\n",
            "Loss: 2.627e-06\n",
            "Loss: 2.626e-06\n",
            "Loss: 2.624e-06\n",
            "Loss: 2.621e-06\n",
            "Loss: 2.619e-06\n",
            "Loss: 2.617e-06\n",
            "Loss: 2.615e-06\n",
            "Loss: 2.611e-06\n",
            "Loss: 2.606e-06\n",
            "Loss: 2.604e-06\n",
            "Loss: 2.598e-06\n",
            "Loss: 2.596e-06\n",
            "Loss: 2.590e-06\n",
            "Loss: 2.583e-06\n",
            "Loss: 2.577e-06\n",
            "Loss: 2.573e-06\n",
            "Loss: 2.571e-06\n",
            "Loss: 2.570e-06\n",
            "Loss: 2.568e-06\n",
            "Loss: 2.565e-06\n",
            "Loss: 2.561e-06\n",
            "Loss: 2.568e-06\n",
            "Loss: 2.559e-06\n",
            "Loss: 2.558e-06\n",
            "Loss: 2.556e-06\n",
            "Loss: 2.555e-06\n",
            "Loss: 2.552e-06\n",
            "Loss: 2.551e-06\n",
            "Loss: 2.549e-06\n",
            "Loss: 2.548e-06\n",
            "Loss: 2.547e-06\n",
            "Loss: 2.547e-06\n",
            "Loss: 2.545e-06\n",
            "Loss: 2.545e-06\n",
            "Loss: 2.545e-06\n",
            "Loss: 2.544e-06\n",
            "Loss: 2.543e-06\n",
            "Loss: 2.543e-06\n",
            "Loss: 2.542e-06\n",
            "Loss: 2.541e-06\n",
            "Loss: 2.541e-06\n",
            "Loss: 2.540e-06\n",
            "Loss: 2.540e-06\n",
            "Loss: 2.539e-06\n",
            "Loss: 2.539e-06\n",
            "Loss: 2.538e-06\n",
            "Loss: 2.538e-06\n",
            "Loss: 2.538e-06\n",
            "Loss: 2.537e-06\n",
            "Loss: 2.537e-06\n",
            "Loss: 2.537e-06\n",
            "Loss: 2.537e-06\n",
            "Loss: 2.537e-06\n",
            "Loss: 2.536e-06\n",
            "Loss: 2.536e-06\n",
            "Loss: 2.536e-06\n",
            "Loss: 2.535e-06\n",
            "Loss: 2.534e-06\n",
            "Loss: 2.533e-06\n",
            "Loss: 2.533e-06\n",
            "Loss: 2.533e-06\n",
            "Loss: 2.532e-06\n",
            "Loss: 2.531e-06\n",
            "Loss: 2.530e-06\n",
            "Loss: 2.530e-06\n",
            "Loss: 2.530e-06\n",
            "Loss: 2.529e-06\n",
            "Loss: 2.529e-06\n",
            "Loss: 2.528e-06\n",
            "Loss: 2.527e-06\n",
            "Loss: 2.526e-06\n",
            "Loss: 2.528e-06\n",
            "Loss: 2.526e-06\n",
            "Loss: 2.525e-06\n",
            "Loss: 2.525e-06\n",
            "Loss: 2.524e-06\n",
            "Loss: 2.524e-06\n",
            "Loss: 2.523e-06\n",
            "Loss: 2.522e-06\n",
            "Loss: 2.522e-06\n",
            "Loss: 2.522e-06\n",
            "Loss: 2.520e-06\n",
            "Loss: 2.523e-06\n",
            "Loss: 2.519e-06\n",
            "Loss: 2.518e-06\n",
            "Loss: 2.516e-06\n",
            "Loss: 2.515e-06\n",
            "Loss: 2.513e-06\n",
            "Loss: 2.512e-06\n",
            "Loss: 2.511e-06\n",
            "Loss: 2.510e-06\n",
            "Loss: 2.510e-06\n",
            "Loss: 2.510e-06\n",
            "Loss: 2.509e-06\n",
            "Loss: 2.508e-06\n",
            "Loss: 2.507e-06\n",
            "Loss: 2.506e-06\n",
            "Loss: 2.505e-06\n",
            "Loss: 2.504e-06\n",
            "Loss: 2.503e-06\n",
            "Loss: 2.502e-06\n",
            "Loss: 2.502e-06\n",
            "Loss: 2.502e-06\n",
            "Loss: 2.501e-06\n",
            "Loss: 2.501e-06\n",
            "Loss: 2.500e-06\n",
            "Loss: 2.498e-06\n",
            "Loss: 2.496e-06\n",
            "Loss: 2.494e-06\n",
            "Loss: 2.493e-06\n",
            "Loss: 2.492e-06\n",
            "Loss: 2.489e-06\n",
            "Loss: 2.486e-06\n",
            "Loss: 2.484e-06\n",
            "Loss: 2.481e-06\n",
            "Loss: 2.479e-06\n",
            "Loss: 2.477e-06\n",
            "Loss: 2.475e-06\n",
            "Loss: 2.474e-06\n",
            "Loss: 2.473e-06\n",
            "Loss: 2.472e-06\n",
            "Loss: 2.471e-06\n",
            "Loss: 2.469e-06\n",
            "Loss: 2.467e-06\n",
            "Loss: 2.466e-06\n",
            "Loss: 2.464e-06\n",
            "Loss: 2.463e-06\n",
            "Loss: 2.463e-06\n",
            "Loss: 2.460e-06\n",
            "Loss: 2.458e-06\n",
            "Loss: 2.456e-06\n",
            "Loss: 2.454e-06\n",
            "Loss: 2.454e-06\n",
            "Loss: 2.451e-06\n",
            "Loss: 2.450e-06\n",
            "Loss: 2.449e-06\n",
            "Loss: 2.447e-06\n",
            "Loss: 2.446e-06\n",
            "Loss: 2.444e-06\n",
            "Loss: 2.444e-06\n",
            "Loss: 2.443e-06\n",
            "Loss: 2.443e-06\n",
            "Loss: 2.442e-06\n",
            "Loss: 2.441e-06\n",
            "Loss: 2.441e-06\n",
            "Loss: 2.440e-06\n",
            "Loss: 2.439e-06\n",
            "Loss: 2.437e-06\n",
            "Loss: 2.436e-06\n",
            "Loss: 2.434e-06\n",
            "Loss: 2.433e-06\n",
            "Loss: 2.431e-06\n",
            "Loss: 2.429e-06\n",
            "Loss: 2.428e-06\n",
            "Loss: 2.427e-06\n",
            "Loss: 2.425e-06\n",
            "Loss: 2.425e-06\n",
            "Loss: 2.424e-06\n",
            "Loss: 2.423e-06\n",
            "Loss: 2.422e-06\n",
            "Loss: 2.422e-06\n",
            "Loss: 2.421e-06\n",
            "Loss: 2.421e-06\n",
            "Loss: 2.420e-06\n",
            "Loss: 2.419e-06\n",
            "Loss: 2.419e-06\n",
            "Loss: 2.418e-06\n",
            "Loss: 2.418e-06\n",
            "Loss: 2.417e-06\n",
            "Loss: 2.417e-06\n",
            "Loss: 2.416e-06\n",
            "Loss: 2.415e-06\n",
            "Loss: 2.414e-06\n",
            "Loss: 2.413e-06\n",
            "Loss: 2.412e-06\n",
            "Loss: 2.411e-06\n",
            "Loss: 2.410e-06\n",
            "Loss: 2.409e-06\n",
            "Loss: 2.408e-06\n",
            "Loss: 2.406e-06\n",
            "Loss: 2.404e-06\n",
            "Loss: 2.402e-06\n",
            "Loss: 2.400e-06\n",
            "Loss: 2.400e-06\n",
            "Loss: 2.398e-06\n",
            "Loss: 2.396e-06\n",
            "Loss: 2.395e-06\n",
            "Loss: 2.394e-06\n",
            "Loss: 2.393e-06\n",
            "Loss: 2.392e-06\n",
            "Loss: 2.392e-06\n",
            "Loss: 2.391e-06\n",
            "Loss: 2.390e-06\n",
            "Loss: 2.389e-06\n",
            "Loss: 2.388e-06\n",
            "Loss: 2.386e-06\n",
            "Loss: 2.386e-06\n",
            "Loss: 2.384e-06\n",
            "Loss: 2.382e-06\n",
            "Loss: 2.380e-06\n",
            "Loss: 2.381e-06\n",
            "Loss: 2.380e-06\n",
            "Loss: 2.378e-06\n",
            "Loss: 2.377e-06\n",
            "Loss: 2.376e-06\n",
            "Loss: 2.375e-06\n",
            "Loss: 2.372e-06\n",
            "Loss: 2.369e-06\n",
            "Loss: 2.386e-06\n",
            "Loss: 2.367e-06\n",
            "Loss: 2.366e-06\n",
            "Loss: 2.365e-06\n",
            "Loss: 2.365e-06\n",
            "Loss: 2.363e-06\n",
            "Loss: 2.362e-06\n",
            "Loss: 2.362e-06\n",
            "Loss: 2.360e-06\n",
            "Loss: 2.359e-06\n",
            "Loss: 2.357e-06\n",
            "Loss: 2.355e-06\n",
            "Loss: 2.353e-06\n",
            "Loss: 2.350e-06\n",
            "Loss: 2.348e-06\n",
            "Loss: 2.346e-06\n",
            "Loss: 2.344e-06\n",
            "Loss: 2.341e-06\n",
            "Loss: 2.338e-06\n",
            "Loss: 2.336e-06\n",
            "Loss: 2.335e-06\n",
            "Loss: 2.333e-06\n",
            "Loss: 2.331e-06\n",
            "Loss: 2.330e-06\n",
            "Loss: 2.330e-06\n",
            "Loss: 2.328e-06\n",
            "Loss: 2.328e-06\n",
            "Loss: 2.327e-06\n",
            "Loss: 2.326e-06\n",
            "Loss: 2.324e-06\n",
            "Loss: 2.323e-06\n",
            "Loss: 2.323e-06\n",
            "Loss: 2.322e-06\n",
            "Loss: 2.321e-06\n",
            "Loss: 2.321e-06\n",
            "Loss: 2.320e-06\n",
            "Loss: 2.320e-06\n",
            "Loss: 2.319e-06\n",
            "Loss: 2.319e-06\n",
            "Loss: 2.317e-06\n",
            "Loss: 2.316e-06\n",
            "Loss: 2.314e-06\n",
            "Loss: 2.313e-06\n",
            "Loss: 2.312e-06\n",
            "Loss: 2.311e-06\n",
            "Loss: 2.310e-06\n",
            "Loss: 2.310e-06\n",
            "Loss: 2.309e-06\n",
            "Loss: 2.313e-06\n",
            "Loss: 2.308e-06\n",
            "Loss: 2.308e-06\n",
            "Loss: 2.307e-06\n",
            "Loss: 2.306e-06\n",
            "Loss: 2.304e-06\n",
            "Loss: 2.302e-06\n",
            "Loss: 2.308e-06\n",
            "Loss: 2.301e-06\n",
            "Loss: 2.298e-06\n",
            "Loss: 2.296e-06\n",
            "Loss: 2.295e-06\n",
            "Loss: 2.294e-06\n",
            "Loss: 2.293e-06\n",
            "Loss: 2.292e-06\n",
            "Loss: 2.291e-06\n",
            "Loss: 2.289e-06\n",
            "Loss: 2.287e-06\n",
            "Loss: 2.284e-06\n",
            "Loss: 2.281e-06\n",
            "Loss: 2.279e-06\n",
            "Loss: 2.277e-06\n",
            "Loss: 2.276e-06\n",
            "Loss: 2.272e-06\n",
            "Loss: 2.270e-06\n",
            "Loss: 2.268e-06\n",
            "Loss: 2.266e-06\n",
            "Loss: 2.265e-06\n",
            "Loss: 2.265e-06\n",
            "Loss: 2.264e-06\n",
            "Loss: 2.263e-06\n",
            "Loss: 2.262e-06\n",
            "Loss: 2.260e-06\n",
            "Loss: 2.259e-06\n",
            "Loss: 2.258e-06\n",
            "Loss: 2.256e-06\n",
            "Loss: 2.254e-06\n",
            "Loss: 2.253e-06\n",
            "Loss: 2.253e-06\n",
            "Loss: 2.251e-06\n",
            "Loss: 2.250e-06\n",
            "Loss: 2.248e-06\n",
            "Loss: 2.247e-06\n",
            "Loss: 2.247e-06\n",
            "Loss: 2.246e-06\n",
            "Loss: 2.246e-06\n",
            "Loss: 2.245e-06\n",
            "Loss: 2.245e-06\n",
            "Loss: 2.244e-06\n",
            "Loss: 2.244e-06\n",
            "Loss: 2.243e-06\n",
            "Loss: 2.243e-06\n",
            "Loss: 2.243e-06\n",
            "Loss: 2.243e-06\n",
            "Loss: 2.242e-06\n",
            "Loss: 2.242e-06\n",
            "Loss: 2.241e-06\n",
            "Loss: 2.241e-06\n",
            "Loss: 2.241e-06\n",
            "Loss: 2.240e-06\n",
            "Loss: 2.240e-06\n",
            "Loss: 2.241e-06\n",
            "Loss: 2.239e-06\n",
            "Loss: 2.239e-06\n",
            "Loss: 2.238e-06\n",
            "Loss: 2.237e-06\n",
            "Loss: 2.236e-06\n",
            "Loss: 2.235e-06\n",
            "Loss: 2.234e-06\n",
            "Loss: 2.233e-06\n",
            "Loss: 2.232e-06\n",
            "Loss: 2.232e-06\n",
            "Loss: 2.230e-06\n",
            "Loss: 2.229e-06\n",
            "Loss: 2.228e-06\n",
            "Loss: 2.228e-06\n",
            "Loss: 2.227e-06\n",
            "Loss: 2.226e-06\n",
            "Loss: 2.231e-06\n",
            "Loss: 2.225e-06\n",
            "Loss: 2.225e-06\n",
            "Loss: 2.223e-06\n",
            "Loss: 2.222e-06\n",
            "Loss: 2.232e-06\n",
            "Loss: 2.222e-06\n",
            "Loss: 2.221e-06\n",
            "Loss: 2.220e-06\n",
            "Loss: 2.220e-06\n",
            "Loss: 2.219e-06\n",
            "Loss: 2.219e-06\n",
            "Loss: 2.217e-06\n",
            "Loss: 2.219e-06\n",
            "Loss: 2.216e-06\n",
            "Loss: 2.215e-06\n",
            "Loss: 2.214e-06\n",
            "Loss: 2.212e-06\n",
            "Loss: 2.211e-06\n",
            "Loss: 2.209e-06\n",
            "Loss: 2.206e-06\n",
            "Loss: 2.205e-06\n",
            "Loss: 2.204e-06\n",
            "Loss: 2.211e-06\n",
            "Loss: 2.203e-06\n",
            "Loss: 2.202e-06\n",
            "Loss: 2.201e-06\n",
            "Loss: 2.199e-06\n",
            "Loss: 2.197e-06\n",
            "Loss: 2.199e-06\n",
            "Loss: 2.196e-06\n",
            "Loss: 2.193e-06\n",
            "Loss: 2.192e-06\n",
            "Loss: 2.191e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.635e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "Loss: 2.190e-06\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000002\n",
            "  Number of iterations: 2671\n",
            "  Number of functions evaluations: 2820\n",
            "Training time: 487.2362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f33c9fd3fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuGpp0je41Yl"
      },
      "source": [
        "def exact_solution(x, y):\n",
        "    u = tf.math.sin(np.pi*x)*tf.math.sin(np.pi*y)\n",
        "    return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49VsFHof3D3i"
      },
      "source": [
        "datasetTest = np.genfromtxt('test_data.txt', delimiter=',')\n",
        "x,y,xb,yb,ub = splitData(datasetTest)\n",
        "x = x.reshape((x.size, 1, 1))\n",
        "y = y.reshape((y.size, 1, 1))\n",
        "xb = xb.reshape((xb.size, 1, 1))\n",
        "yb = yb.reshape((yb.size, 1, 1))\n",
        "ub = ub.reshape((ub.size, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mifChj8VL9Xr"
      },
      "source": [
        "dataset = np.genfromtxt('data_500.csv', delimiter=',')\n",
        "# x, y, xb, yb, ub, vb = splitData(dataset)\n",
        "x = dataset[:,0]\n",
        "x = x.reshape((x.size, 1, 1))\n",
        "y = dataset[:,1]\n",
        "y = y.reshape((y.size, 1, 1))\n",
        "xb = dataset[:,2]\n",
        "xb = xb.reshape((xb.size, 1, 1))\n",
        "yb = dataset[:,3]\n",
        "yb = yb.reshape((yb.size, 1, 1))\n",
        "ub = dataset[:,4]\n",
        "ub = ub.reshape((ub.size, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY5IoFcX5uVF"
      },
      "source": [
        "# ub_e = exact_solution(xb, yb)\n",
        "u_e = exact_solution(x, y)\n",
        "u_e = tf.reshape(u_e, [x.size, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8I1fh4-5y_N"
      },
      "source": [
        "u_pred = model.predict(x, y)\n",
        "ub_pred = model.predict(xb, yb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GAmKlTqmQRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f07509e-5df6-44d9-cb0c-0100c2624928"
      },
      "source": [
        "LossL2_u = tf.reduce_mean(tf.square(u_pred - u_e))\n",
        "with tf.Session() as sess:\n",
        "    result = LossL2_u.eval()\n",
        "\n",
        "    print(result) \n",
        "\n",
        "    print(type(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.921680083575608e-07\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlJGRtHtwM0e",
        "outputId": "cb9bb10b-819b-4c3a-a09d-1c645b35e1fc"
      },
      "source": [
        "LossL2_u= tf.math.sqrt(LossL2_u)\n",
        "with tf.Session() as sess:\n",
        "    result = LossL2_u.eval()\n",
        "\n",
        "    print(result) \n",
        "\n",
        "    print(type(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000322340128893508\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8BoQ2SC6Sdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da33a39-4164-457f-90e6-851a2b947e5d"
      },
      "source": [
        "LossL2 = tf.reduce_mean(tf.square(u_pred - u_e)) + tf.reduce_mean(tf.square(ub_pred - ub))\n",
        "with tf.Session() as sess:\n",
        "    result = LossL2.eval()\n",
        "\n",
        "    print(result) \n",
        "\n",
        "    print(type(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.178817879791047e-07\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6pxqf0IwrVa",
        "outputId": "6275dc95-ee72-4f8e-ce31-55b9ef20da62"
      },
      "source": [
        "LossL2= tf.math.sqrt(LossL2)\n",
        "with tf.Session() as sess:\n",
        "    result = LossL2.eval()\n",
        "\n",
        "    print(result) \n",
        "\n",
        "    print(type(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0007196400405613245\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68-IOVR1L3HT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZRIsOj-i1xa"
      },
      "source": [
        "newModel = PDENet(xb, yb, ub, x, y, layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbeShVxKi4Ti"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "newModel.saver.restore(newModel.sess, 'my-model.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}